{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14_bInnZ-wHYz272Lw_nubHDUj4z9WLgR","timestamp":1715353441721}],"authorship_tag":"ABX9TyOcQjk0hskP3rc394d8sdDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tensorflow==2.16.1\n","!pip install keras==3.1.1"],"metadata":{"id":"mBhcnJLKgT3A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715353586805,"user_tz":-60,"elapsed":110492,"user":{"displayName":"by tan","userId":"09012215015310927543"}},"outputId":"e101fd16-a2b7-41ad-e826-9906ef8c71e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.16.1\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow==2.16.1)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.63.0)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras>=3.0.0 (from tensorflow==2.16.1)\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.7.1)\n","Collecting namex (from keras>=3.0.0->tensorflow==2.16.1)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras>=3.0.0->tensorflow==2.16.1)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n","Collecting keras==3.1.1\n","  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (1.25.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.11.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.3.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras==3.1.1) (4.11.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.1.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.1.1) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.1.1) (0.1.2)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.3.3\n","    Uninstalling keras-3.3.3:\n","      Successfully uninstalled keras-3.3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.1.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqFAjv2EYe8V","outputId":"0196cb2a-448c-4c22-e06b-0e797f0b0ca2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.4809 - loss: 5.0371 - val_accuracy: 0.5076 - val_loss: 3.9132\n","Epoch 2/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5200 - loss: 3.6329 - val_accuracy: 0.5001 - val_loss: 3.8626\n","Epoch 3/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.5152 - loss: 3.5965 - val_accuracy: 0.4989 - val_loss: 3.8834\n","Epoch 4/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.5265 - loss: 3.5215 - val_accuracy: 0.5057 - val_loss: 3.8417\n","Epoch 5/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.5257 - loss: 3.5111 - val_accuracy: 0.5092 - val_loss: 3.9350\n","Epoch 6/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5345 - loss: 3.4049 - val_accuracy: 0.5070 - val_loss: 3.8228\n","Epoch 7/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5243 - loss: 3.4285 - val_accuracy: 0.5030 - val_loss: 3.8717\n","Epoch 8/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.5239 - loss: 3.4215 - val_accuracy: 0.4997 - val_loss: 3.9087\n","Epoch 9/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5213 - loss: 3.4260 - val_accuracy: 0.5087 - val_loss: 4.0460\n","Epoch 10/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5241 - loss: 3.3720 - val_accuracy: 0.5046 - val_loss: 3.9142\n","Epoch 11/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step - accuracy: 0.5347 - loss: 3.2655 - val_accuracy: 0.4991 - val_loss: 3.9129\n","Epoch 12/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5314 - loss: 3.2861 - val_accuracy: 0.5005 - val_loss: 3.9259\n","Epoch 13/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step - accuracy: 0.5252 - loss: 3.2937 - val_accuracy: 0.5056 - val_loss: 3.9265\n","Epoch 14/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.5264 - loss: 3.2705 - val_accuracy: 0.4998 - val_loss: 4.1027\n","Epoch 15/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5374 - loss: 3.1737 - val_accuracy: 0.4939 - val_loss: 3.9781\n","Epoch 16/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.5295 - loss: 3.2210 - val_accuracy: 0.4854 - val_loss: 4.2489\n","Epoch 17/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5210 - loss: 3.2517 - val_accuracy: 0.4961 - val_loss: 4.1983\n","Epoch 18/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.5328 - loss: 3.1484 - val_accuracy: 0.4975 - val_loss: 4.1477\n","Epoch 19/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.5301 - loss: 3.1550 - val_accuracy: 0.4934 - val_loss: 4.1501\n","Epoch 20/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5324 - loss: 3.1194 - val_accuracy: 0.4956 - val_loss: 4.2257\n","Epoch 21/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5343 - loss: 3.0844 - val_accuracy: 0.4846 - val_loss: 4.3506\n","Epoch 22/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.5361 - loss: 3.0508 - val_accuracy: 0.4863 - val_loss: 4.1734\n","Epoch 23/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.5325 - loss: 3.0611 - val_accuracy: 0.4910 - val_loss: 4.2840\n","Epoch 24/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.5321 - loss: 3.0321 - val_accuracy: 0.4785 - val_loss: 4.3643\n","Epoch 25/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5239 - loss: 3.0447 - val_accuracy: 0.4839 - val_loss: 4.3326\n","Epoch 26/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5351 - loss: 2.9785 - val_accuracy: 0.4830 - val_loss: 4.3521\n","Epoch 27/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5332 - loss: 2.9803 - val_accuracy: 0.4849 - val_loss: 4.4343\n","Epoch 28/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5402 - loss: 2.8967 - val_accuracy: 0.4809 - val_loss: 4.3904\n","Epoch 29/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5256 - loss: 2.9741 - val_accuracy: 0.4761 - val_loss: 4.4313\n","Epoch 30/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5353 - loss: 2.9106 - val_accuracy: 0.4872 - val_loss: 4.4390\n","Epoch 31/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5430 - loss: 2.8355 - val_accuracy: 0.4821 - val_loss: 4.3974\n","Epoch 32/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5277 - loss: 2.9185 - val_accuracy: 0.4796 - val_loss: 4.4185\n","Epoch 33/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5451 - loss: 2.7914 - val_accuracy: 0.4783 - val_loss: 4.5546\n","Epoch 34/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.5394 - loss: 2.8040 - val_accuracy: 0.4749 - val_loss: 4.5444\n","Epoch 35/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.5462 - loss: 2.7433 - val_accuracy: 0.4783 - val_loss: 4.5274\n","Epoch 36/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5413 - loss: 2.7719 - val_accuracy: 0.4755 - val_loss: 4.5427\n","Epoch 37/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5341 - loss: 2.7971 - val_accuracy: 0.4731 - val_loss: 4.6714\n","Epoch 38/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5460 - loss: 2.7060 - val_accuracy: 0.4712 - val_loss: 4.7071\n","Epoch 39/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5371 - loss: 2.7720 - val_accuracy: 0.4767 - val_loss: 4.5585\n","Epoch 40/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5496 - loss: 2.6614 - val_accuracy: 0.4714 - val_loss: 4.5905\n","Epoch 41/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.5519 - loss: 2.6351 - val_accuracy: 0.4676 - val_loss: 4.7006\n","Epoch 42/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5495 - loss: 2.6225 - val_accuracy: 0.4661 - val_loss: 4.7321\n","Epoch 43/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.5495 - loss: 2.6211 - val_accuracy: 0.4743 - val_loss: 4.7496\n","Epoch 44/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5528 - loss: 2.5937 - val_accuracy: 0.4734 - val_loss: 4.7340\n","Epoch 45/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5541 - loss: 2.5732 - val_accuracy: 0.4641 - val_loss: 4.7766\n","Epoch 46/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5548 - loss: 2.5469 - val_accuracy: 0.4709 - val_loss: 4.8024\n","Epoch 47/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.5552 - loss: 2.5314 - val_accuracy: 0.4680 - val_loss: 4.7965\n","Epoch 48/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.5541 - loss: 2.5235 - val_accuracy: 0.4711 - val_loss: 4.7112\n","Epoch 49/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5505 - loss: 2.5475 - val_accuracy: 0.4689 - val_loss: 4.8408\n","Epoch 50/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.5524 - loss: 2.5259 - val_accuracy: 0.4646 - val_loss: 4.9324\n","Epoch 51/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5590 - loss: 2.4782 - val_accuracy: 0.4691 - val_loss: 4.9898\n","Epoch 52/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5549 - loss: 2.4787 - val_accuracy: 0.4669 - val_loss: 4.8219\n","Epoch 53/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5618 - loss: 2.4437 - val_accuracy: 0.4723 - val_loss: 4.8730\n","Epoch 54/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.5652 - loss: 2.4198 - val_accuracy: 0.4649 - val_loss: 4.9183\n","Epoch 55/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5460 - loss: 2.4992 - val_accuracy: 0.4659 - val_loss: 4.9781\n","Epoch 56/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.5613 - loss: 2.4159 - val_accuracy: 0.4716 - val_loss: 4.9788\n","Epoch 57/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5618 - loss: 2.4041 - val_accuracy: 0.4708 - val_loss: 4.9585\n","Epoch 58/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.5739 - loss: 2.3155 - val_accuracy: 0.4685 - val_loss: 4.9126\n","Epoch 59/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5569 - loss: 2.4022 - val_accuracy: 0.4641 - val_loss: 5.0970\n","Epoch 60/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5743 - loss: 2.2941 - val_accuracy: 0.4644 - val_loss: 5.0117\n","Epoch 61/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5639 - loss: 2.3557 - val_accuracy: 0.4634 - val_loss: 4.9355\n","Epoch 62/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.5713 - loss: 2.3116 - val_accuracy: 0.4664 - val_loss: 5.1448\n","Epoch 63/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5630 - loss: 2.3409 - val_accuracy: 0.4576 - val_loss: 5.1035\n","Epoch 64/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5771 - loss: 2.2492 - val_accuracy: 0.4601 - val_loss: 5.1177\n","Epoch 65/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5717 - loss: 2.2852 - val_accuracy: 0.4679 - val_loss: 5.0769\n","Epoch 66/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5629 - loss: 2.3089 - val_accuracy: 0.4654 - val_loss: 5.1149\n","Epoch 67/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5692 - loss: 2.2800 - val_accuracy: 0.4536 - val_loss: 5.1790\n","Epoch 68/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5755 - loss: 2.2385 - val_accuracy: 0.4556 - val_loss: 5.2190\n","Epoch 69/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.5673 - loss: 2.2654 - val_accuracy: 0.4582 - val_loss: 5.2439\n","Epoch 70/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5823 - loss: 2.1756 - val_accuracy: 0.4643 - val_loss: 5.1577\n","Epoch 71/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5784 - loss: 2.2052 - val_accuracy: 0.4606 - val_loss: 5.1362\n","Epoch 72/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5829 - loss: 2.1726 - val_accuracy: 0.4603 - val_loss: 5.2926\n","Epoch 73/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5796 - loss: 2.1769 - val_accuracy: 0.4549 - val_loss: 5.2075\n","Epoch 74/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.5757 - loss: 2.2014 - val_accuracy: 0.4655 - val_loss: 5.2284\n","Epoch 75/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5913 - loss: 2.1155 - val_accuracy: 0.4617 - val_loss: 5.2490\n","Epoch 76/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5812 - loss: 2.1418 - val_accuracy: 0.4533 - val_loss: 5.2983\n","Epoch 77/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5880 - loss: 2.1055 - val_accuracy: 0.4591 - val_loss: 5.3666\n","Epoch 78/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.5816 - loss: 2.1382 - val_accuracy: 0.4588 - val_loss: 5.1836\n","Epoch 79/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5871 - loss: 2.1025 - val_accuracy: 0.4602 - val_loss: 5.3469\n","Epoch 80/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5858 - loss: 2.1040 - val_accuracy: 0.4531 - val_loss: 5.3206\n","Epoch 81/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5897 - loss: 2.0684 - val_accuracy: 0.4500 - val_loss: 5.4378\n","Epoch 82/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.5845 - loss: 2.0948 - val_accuracy: 0.4540 - val_loss: 5.3874\n","Epoch 83/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5895 - loss: 2.0653 - val_accuracy: 0.4591 - val_loss: 5.3483\n","Epoch 84/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6002 - loss: 2.0021 - val_accuracy: 0.4561 - val_loss: 5.3531\n","Epoch 85/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5917 - loss: 2.0604 - val_accuracy: 0.4516 - val_loss: 5.4398\n","Epoch 86/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.5957 - loss: 2.0176 - val_accuracy: 0.4539 - val_loss: 5.4291\n","Epoch 87/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5955 - loss: 2.0169 - val_accuracy: 0.4545 - val_loss: 5.4266\n","Epoch 88/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.5916 - loss: 2.0311 - val_accuracy: 0.4603 - val_loss: 5.4419\n","Epoch 89/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.5939 - loss: 2.0058 - val_accuracy: 0.4510 - val_loss: 5.5425\n","Epoch 90/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.5987 - loss: 1.9863 - val_accuracy: 0.4544 - val_loss: 5.5676\n","Epoch 91/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.5922 - loss: 1.9956 - val_accuracy: 0.4570 - val_loss: 5.4773\n","Epoch 92/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6000 - loss: 1.9648 - val_accuracy: 0.4561 - val_loss: 5.5062\n","Epoch 93/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5974 - loss: 1.9662 - val_accuracy: 0.4460 - val_loss: 5.5354\n","Epoch 94/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.5975 - loss: 1.9653 - val_accuracy: 0.4517 - val_loss: 5.5674\n","Epoch 95/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.6024 - loss: 1.9470 - val_accuracy: 0.4561 - val_loss: 5.5084\n","Epoch 96/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.5973 - loss: 1.9631 - val_accuracy: 0.4600 - val_loss: 5.5320\n","Epoch 97/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.5949 - loss: 1.9668 - val_accuracy: 0.4542 - val_loss: 5.5854\n","Epoch 98/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.5892 - loss: 1.9901 - val_accuracy: 0.4505 - val_loss: 5.6606\n","Epoch 99/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5989 - loss: 1.9253 - val_accuracy: 0.4521 - val_loss: 5.6232\n","Epoch 100/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.6024 - loss: 1.9206 - val_accuracy: 0.4507 - val_loss: 5.5356\n","Epoch 101/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6067 - loss: 1.8951 - val_accuracy: 0.4492 - val_loss: 5.5772\n","Epoch 102/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6083 - loss: 1.8737 - val_accuracy: 0.4523 - val_loss: 5.7092\n","Epoch 103/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6059 - loss: 1.8971 - val_accuracy: 0.4431 - val_loss: 5.6713\n","Epoch 104/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6050 - loss: 1.8887 - val_accuracy: 0.4512 - val_loss: 5.6148\n","Epoch 105/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6040 - loss: 1.8875 - val_accuracy: 0.4508 - val_loss: 5.6582\n","Epoch 106/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6079 - loss: 1.8717 - val_accuracy: 0.4473 - val_loss: 5.6873\n","Epoch 107/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6099 - loss: 1.8469 - val_accuracy: 0.4455 - val_loss: 5.6807\n","Epoch 108/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.6059 - loss: 1.8737 - val_accuracy: 0.4488 - val_loss: 5.6616\n","Epoch 109/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.6169 - loss: 1.8058 - val_accuracy: 0.4534 - val_loss: 5.6542\n","Epoch 110/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6105 - loss: 1.8300 - val_accuracy: 0.4501 - val_loss: 5.6293\n","Epoch 111/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.6129 - loss: 1.8270 - val_accuracy: 0.4464 - val_loss: 5.7736\n","Epoch 112/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.6155 - loss: 1.8093 - val_accuracy: 0.4424 - val_loss: 5.7157\n","Epoch 113/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6183 - loss: 1.7892 - val_accuracy: 0.4542 - val_loss: 5.7194\n","Epoch 114/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6092 - loss: 1.8233 - val_accuracy: 0.4471 - val_loss: 5.7268\n","Epoch 115/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6125 - loss: 1.8067 - val_accuracy: 0.4459 - val_loss: 5.7697\n","Epoch 116/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6084 - loss: 1.8246 - val_accuracy: 0.4436 - val_loss: 5.7955\n","Epoch 117/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6117 - loss: 1.8201 - val_accuracy: 0.4552 - val_loss: 5.6838\n","Epoch 118/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6130 - loss: 1.7873 - val_accuracy: 0.4480 - val_loss: 5.7384\n","Epoch 119/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6153 - loss: 1.7922 - val_accuracy: 0.4465 - val_loss: 5.8180\n","Epoch 120/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 1.7492 - val_accuracy: 0.4420 - val_loss: 5.7930\n","Epoch 121/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6172 - loss: 1.7767 - val_accuracy: 0.4505 - val_loss: 5.8142\n","Epoch 122/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6153 - loss: 1.7823 - val_accuracy: 0.4468 - val_loss: 5.7557\n","Epoch 123/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6187 - loss: 1.7594 - val_accuracy: 0.4430 - val_loss: 5.8033\n","Epoch 124/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6182 - loss: 1.7607 - val_accuracy: 0.4422 - val_loss: 5.8473\n","Epoch 125/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6180 - loss: 1.7618 - val_accuracy: 0.4400 - val_loss: 5.8770\n","Epoch 126/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6165 - loss: 1.7492 - val_accuracy: 0.4410 - val_loss: 5.6989\n","Epoch 127/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.6154 - loss: 1.7613 - val_accuracy: 0.4481 - val_loss: 5.8363\n","Epoch 128/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.6086 - loss: 1.8026 - val_accuracy: 0.4348 - val_loss: 5.9170\n","Epoch 129/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6131 - loss: 1.7834 - val_accuracy: 0.4443 - val_loss: 5.9098\n","Epoch 130/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6223 - loss: 1.7223 - val_accuracy: 0.4446 - val_loss: 5.8610\n","Epoch 131/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6118 - loss: 1.7781 - val_accuracy: 0.4447 - val_loss: 5.9274\n","Epoch 132/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6220 - loss: 1.7349 - val_accuracy: 0.4446 - val_loss: 5.9590\n","Epoch 133/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6175 - loss: 1.7497 - val_accuracy: 0.4362 - val_loss: 5.9486\n","Epoch 134/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6153 - loss: 1.7565 - val_accuracy: 0.4475 - val_loss: 5.9448\n","Epoch 135/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6250 - loss: 1.7167 - val_accuracy: 0.4418 - val_loss: 5.9418\n","Epoch 136/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6100 - loss: 1.7639 - val_accuracy: 0.4414 - val_loss: 5.9701\n","Epoch 137/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6209 - loss: 1.7349 - val_accuracy: 0.4386 - val_loss: 5.9426\n","Epoch 138/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6165 - loss: 1.7363 - val_accuracy: 0.4438 - val_loss: 5.9469\n","Epoch 139/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6169 - loss: 1.7409 - val_accuracy: 0.4407 - val_loss: 5.8669\n","Epoch 140/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6274 - loss: 1.6815 - val_accuracy: 0.4400 - val_loss: 5.8982\n","Epoch 141/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6220 - loss: 1.7087 - val_accuracy: 0.4389 - val_loss: 6.0583\n","Epoch 142/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6230 - loss: 1.6917 - val_accuracy: 0.4375 - val_loss: 6.0846\n","Epoch 143/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6249 - loss: 1.6942 - val_accuracy: 0.4442 - val_loss: 5.9677\n","Epoch 144/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6184 - loss: 1.7142 - val_accuracy: 0.4385 - val_loss: 6.0394\n","Epoch 145/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6178 - loss: 1.7192 - val_accuracy: 0.4411 - val_loss: 6.1227\n","Epoch 146/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6245 - loss: 1.6762 - val_accuracy: 0.4389 - val_loss: 6.1366\n","Epoch 147/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6301 - loss: 1.6554 - val_accuracy: 0.4375 - val_loss: 5.9806\n","Epoch 148/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6165 - loss: 1.7128 - val_accuracy: 0.4435 - val_loss: 6.0841\n","Epoch 149/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6207 - loss: 1.6911 - val_accuracy: 0.4426 - val_loss: 5.9911\n","Epoch 150/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 1.6765 - val_accuracy: 0.4367 - val_loss: 6.0242\n","Epoch 151/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6275 - loss: 1.6594 - val_accuracy: 0.4386 - val_loss: 6.0467\n","Epoch 152/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6218 - loss: 1.6891 - val_accuracy: 0.4386 - val_loss: 6.0261\n","Epoch 153/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6206 - loss: 1.6947 - val_accuracy: 0.4357 - val_loss: 6.0379\n","Epoch 154/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6269 - loss: 1.6495 - val_accuracy: 0.4308 - val_loss: 6.0878\n","Epoch 155/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6260 - loss: 1.6506 - val_accuracy: 0.4387 - val_loss: 6.1413\n","Epoch 156/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6257 - loss: 1.6518 - val_accuracy: 0.4409 - val_loss: 6.0717\n","Epoch 157/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 1.6627 - val_accuracy: 0.4435 - val_loss: 6.1421\n","Epoch 158/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6352 - loss: 1.6172 - val_accuracy: 0.4343 - val_loss: 6.1650\n","Epoch 159/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6164 - loss: 1.6873 - val_accuracy: 0.4340 - val_loss: 6.1149\n","Epoch 160/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6288 - loss: 1.6470 - val_accuracy: 0.4395 - val_loss: 6.1284\n","Epoch 161/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6388 - loss: 1.5847 - val_accuracy: 0.4420 - val_loss: 6.1329\n","Epoch 162/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6353 - loss: 1.6135 - val_accuracy: 0.4398 - val_loss: 6.1266\n","Epoch 163/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6164 - loss: 1.6783 - val_accuracy: 0.4338 - val_loss: 6.2283\n","Epoch 164/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6310 - loss: 1.6306 - val_accuracy: 0.4322 - val_loss: 6.1605\n","Epoch 165/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6297 - loss: 1.6178 - val_accuracy: 0.4357 - val_loss: 6.1200\n","Epoch 166/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6284 - loss: 1.6197 - val_accuracy: 0.4346 - val_loss: 6.0691\n","Epoch 167/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6368 - loss: 1.5916 - val_accuracy: 0.4260 - val_loss: 6.2169\n","Epoch 168/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6283 - loss: 1.6244 - val_accuracy: 0.4304 - val_loss: 6.1925\n","Epoch 169/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6282 - loss: 1.6207 - val_accuracy: 0.4362 - val_loss: 6.0824\n","Epoch 170/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6317 - loss: 1.5972 - val_accuracy: 0.4404 - val_loss: 6.1592\n","Epoch 171/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6242 - loss: 1.6334 - val_accuracy: 0.4323 - val_loss: 6.1648\n","Epoch 172/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6359 - loss: 1.5803 - val_accuracy: 0.4370 - val_loss: 6.2927\n","Epoch 173/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6298 - loss: 1.6043 - val_accuracy: 0.4396 - val_loss: 6.1798\n","Epoch 174/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6312 - loss: 1.5922 - val_accuracy: 0.4419 - val_loss: 6.1577\n","Epoch 175/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6349 - loss: 1.5799 - val_accuracy: 0.4345 - val_loss: 6.2266\n","Epoch 176/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6343 - loss: 1.5749 - val_accuracy: 0.4362 - val_loss: 6.2436\n","Epoch 177/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6384 - loss: 1.5540 - val_accuracy: 0.4342 - val_loss: 6.2752\n","Epoch 178/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6379 - loss: 1.5663 - val_accuracy: 0.4336 - val_loss: 6.0932\n","Epoch 179/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6349 - loss: 1.5665 - val_accuracy: 0.4315 - val_loss: 6.1739\n","Epoch 180/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6480 - loss: 1.5203 - val_accuracy: 0.4319 - val_loss: 6.2832\n","Epoch 181/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6356 - loss: 1.5625 - val_accuracy: 0.4270 - val_loss: 6.2850\n","Epoch 182/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6469 - loss: 1.5034 - val_accuracy: 0.4353 - val_loss: 6.2225\n","Epoch 183/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6339 - loss: 1.5575 - val_accuracy: 0.4375 - val_loss: 6.2363\n","Epoch 184/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6468 - loss: 1.5084 - val_accuracy: 0.4297 - val_loss: 6.2931\n","Epoch 185/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6391 - loss: 1.5456 - val_accuracy: 0.4329 - val_loss: 6.2928\n","Epoch 186/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6303 - loss: 1.5849 - val_accuracy: 0.4335 - val_loss: 6.2836\n","Epoch 187/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6344 - loss: 1.5660 - val_accuracy: 0.4384 - val_loss: 6.2167\n","Epoch 188/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6326 - loss: 1.5604 - val_accuracy: 0.4344 - val_loss: 6.2087\n","Epoch 189/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6382 - loss: 1.5382 - val_accuracy: 0.4325 - val_loss: 6.3205\n","Epoch 190/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6454 - loss: 1.5127 - val_accuracy: 0.4337 - val_loss: 6.3295\n","Epoch 191/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6454 - loss: 1.5016 - val_accuracy: 0.4361 - val_loss: 6.2950\n","Epoch 192/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6460 - loss: 1.5071 - val_accuracy: 0.4371 - val_loss: 6.2841\n","Epoch 193/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6416 - loss: 1.5141 - val_accuracy: 0.4314 - val_loss: 6.3701\n","Epoch 194/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6460 - loss: 1.5029 - val_accuracy: 0.4315 - val_loss: 6.3490\n","Epoch 195/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6431 - loss: 1.5124 - val_accuracy: 0.4377 - val_loss: 6.3383\n","Epoch 196/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6344 - loss: 1.5468 - val_accuracy: 0.4394 - val_loss: 6.3139\n","Epoch 197/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6440 - loss: 1.5019 - val_accuracy: 0.4295 - val_loss: 6.3685\n","Epoch 198/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6384 - loss: 1.5317 - val_accuracy: 0.4258 - val_loss: 6.3897\n","Epoch 199/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6453 - loss: 1.4899 - val_accuracy: 0.4346 - val_loss: 6.3259\n","Epoch 200/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6481 - loss: 1.4725 - val_accuracy: 0.4343 - val_loss: 6.3196\n","Epoch 201/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6419 - loss: 1.5072 - val_accuracy: 0.4320 - val_loss: 6.3255\n","Epoch 202/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6459 - loss: 1.4862 - val_accuracy: 0.4286 - val_loss: 6.3825\n","Epoch 203/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6426 - loss: 1.4956 - val_accuracy: 0.4298 - val_loss: 6.3882\n","Epoch 204/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6446 - loss: 1.4853 - val_accuracy: 0.4348 - val_loss: 6.3604\n","Epoch 205/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6470 - loss: 1.4838 - val_accuracy: 0.4293 - val_loss: 6.3420\n","Epoch 206/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6439 - loss: 1.5037 - val_accuracy: 0.4315 - val_loss: 6.4179\n","Epoch 207/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6359 - loss: 1.5255 - val_accuracy: 0.4289 - val_loss: 6.4443\n","Epoch 208/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6492 - loss: 1.4652 - val_accuracy: 0.4315 - val_loss: 6.3644\n","Epoch 209/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6486 - loss: 1.4644 - val_accuracy: 0.4395 - val_loss: 6.3752\n","Epoch 210/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6427 - loss: 1.4842 - val_accuracy: 0.4308 - val_loss: 6.4967\n","Epoch 211/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6468 - loss: 1.4610 - val_accuracy: 0.4319 - val_loss: 6.4873\n","Epoch 212/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6434 - loss: 1.4852 - val_accuracy: 0.4308 - val_loss: 6.3821\n","Epoch 213/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6539 - loss: 1.4409 - val_accuracy: 0.4374 - val_loss: 6.4047\n","Epoch 214/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6552 - loss: 1.4348 - val_accuracy: 0.4317 - val_loss: 6.3680\n","Epoch 215/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6537 - loss: 1.4390 - val_accuracy: 0.4333 - val_loss: 6.5000\n","Epoch 216/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6513 - loss: 1.4425 - val_accuracy: 0.4325 - val_loss: 6.5004\n","Epoch 217/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6492 - loss: 1.4476 - val_accuracy: 0.4341 - val_loss: 6.3961\n","Epoch 218/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6533 - loss: 1.4300 - val_accuracy: 0.4280 - val_loss: 6.4015\n","Epoch 219/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6524 - loss: 1.4226 - val_accuracy: 0.4278 - val_loss: 6.5012\n","Epoch 220/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6472 - loss: 1.4505 - val_accuracy: 0.4272 - val_loss: 6.5164\n","Epoch 221/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6579 - loss: 1.4152 - val_accuracy: 0.4359 - val_loss: 6.4501\n","Epoch 222/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6494 - loss: 1.4588 - val_accuracy: 0.4400 - val_loss: 6.4437\n","Epoch 223/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6484 - loss: 1.4491 - val_accuracy: 0.4305 - val_loss: 6.4964\n","Epoch 224/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6371 - loss: 1.4989 - val_accuracy: 0.4319 - val_loss: 6.4534\n","Epoch 225/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6483 - loss: 1.4429 - val_accuracy: 0.4336 - val_loss: 6.5315\n","Epoch 226/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6544 - loss: 1.4262 - val_accuracy: 0.4335 - val_loss: 6.4206\n","Epoch 227/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6573 - loss: 1.4118 - val_accuracy: 0.4293 - val_loss: 6.4927\n","Epoch 228/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6591 - loss: 1.3948 - val_accuracy: 0.4320 - val_loss: 6.5315\n","Epoch 229/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6677 - loss: 1.3517 - val_accuracy: 0.4334 - val_loss: 6.5538\n","Epoch 230/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6515 - loss: 1.4351 - val_accuracy: 0.4385 - val_loss: 6.4615\n","Epoch 231/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6532 - loss: 1.4212 - val_accuracy: 0.4346 - val_loss: 6.4735\n","Epoch 232/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6547 - loss: 1.4134 - val_accuracy: 0.4270 - val_loss: 6.5642\n","Epoch 233/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6542 - loss: 1.4119 - val_accuracy: 0.4304 - val_loss: 6.5700\n","Epoch 234/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6588 - loss: 1.3948 - val_accuracy: 0.4388 - val_loss: 6.5303\n","Epoch 235/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6507 - loss: 1.4438 - val_accuracy: 0.4389 - val_loss: 6.5022\n","Epoch 236/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6487 - loss: 1.4274 - val_accuracy: 0.4315 - val_loss: 6.5937\n","Epoch 237/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6546 - loss: 1.4108 - val_accuracy: 0.4299 - val_loss: 6.5643\n","Epoch 238/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6559 - loss: 1.4052 - val_accuracy: 0.4315 - val_loss: 6.5314\n","Epoch 239/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6575 - loss: 1.3986 - val_accuracy: 0.4373 - val_loss: 6.5157\n","Epoch 240/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6591 - loss: 1.3753 - val_accuracy: 0.4308 - val_loss: 6.5645\n","Epoch 241/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6499 - loss: 1.4217 - val_accuracy: 0.4306 - val_loss: 6.6084\n","Epoch 242/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6612 - loss: 1.3739 - val_accuracy: 0.4327 - val_loss: 6.5789\n","Epoch 243/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6569 - loss: 1.4020 - val_accuracy: 0.4333 - val_loss: 6.5666\n","Epoch 244/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6623 - loss: 1.3701 - val_accuracy: 0.4343 - val_loss: 6.5508\n","Epoch 245/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6548 - loss: 1.4118 - val_accuracy: 0.4252 - val_loss: 6.6047\n","Epoch 246/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6526 - loss: 1.4182 - val_accuracy: 0.4292 - val_loss: 6.6334\n","Epoch 247/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6495 - loss: 1.4215 - val_accuracy: 0.4383 - val_loss: 6.5924\n","Epoch 248/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6683 - loss: 1.3516 - val_accuracy: 0.4383 - val_loss: 6.6323\n","Epoch 249/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6570 - loss: 1.3884 - val_accuracy: 0.4322 - val_loss: 6.7038\n","Epoch 250/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6580 - loss: 1.3768 - val_accuracy: 0.4293 - val_loss: 6.7229\n","Epoch 251/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6528 - loss: 1.4134 - val_accuracy: 0.4299 - val_loss: 6.6488\n","Epoch 252/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6575 - loss: 1.3880 - val_accuracy: 0.4339 - val_loss: 6.6300\n","Epoch 253/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6619 - loss: 1.3669 - val_accuracy: 0.4304 - val_loss: 6.5949\n","Epoch 254/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6582 - loss: 1.3833 - val_accuracy: 0.4286 - val_loss: 6.6184\n","Epoch 255/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6627 - loss: 1.3619 - val_accuracy: 0.4251 - val_loss: 6.5724\n","Epoch 256/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6673 - loss: 1.3507 - val_accuracy: 0.4329 - val_loss: 6.5675\n","Epoch 257/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6596 - loss: 1.3702 - val_accuracy: 0.4311 - val_loss: 6.6309\n","Epoch 258/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6559 - loss: 1.3955 - val_accuracy: 0.4274 - val_loss: 6.6649\n","Epoch 259/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6648 - loss: 1.3509 - val_accuracy: 0.4266 - val_loss: 6.7690\n","Epoch 260/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6593 - loss: 1.3703 - val_accuracy: 0.4343 - val_loss: 6.6876\n","Epoch 261/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6618 - loss: 1.3622 - val_accuracy: 0.4339 - val_loss: 6.5957\n","Epoch 262/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6633 - loss: 1.3577 - val_accuracy: 0.4265 - val_loss: 6.6925\n","Epoch 263/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6565 - loss: 1.3751 - val_accuracy: 0.4265 - val_loss: 6.7307\n","Epoch 264/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6585 - loss: 1.3607 - val_accuracy: 0.4339 - val_loss: 6.7227\n","Epoch 265/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6556 - loss: 1.3868 - val_accuracy: 0.4359 - val_loss: 6.6118\n","Epoch 266/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6561 - loss: 1.3810 - val_accuracy: 0.4279 - val_loss: 6.6538\n","Epoch 267/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6587 - loss: 1.3660 - val_accuracy: 0.4315 - val_loss: 6.7146\n","Epoch 268/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6658 - loss: 1.3262 - val_accuracy: 0.4275 - val_loss: 6.6310\n","Epoch 269/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6609 - loss: 1.3589 - val_accuracy: 0.4290 - val_loss: 6.5926\n","Epoch 270/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6615 - loss: 1.3483 - val_accuracy: 0.4301 - val_loss: 6.7316\n","Epoch 271/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6521 - loss: 1.3936 - val_accuracy: 0.4293 - val_loss: 6.7650\n","Epoch 272/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6585 - loss: 1.3647 - val_accuracy: 0.4279 - val_loss: 6.7754\n","Epoch 273/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6660 - loss: 1.3298 - val_accuracy: 0.4303 - val_loss: 6.6541\n","Epoch 274/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6691 - loss: 1.3182 - val_accuracy: 0.4365 - val_loss: 6.7444\n","Epoch 275/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6626 - loss: 1.3572 - val_accuracy: 0.4265 - val_loss: 6.7572\n","Epoch 276/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6507 - loss: 1.4060 - val_accuracy: 0.4298 - val_loss: 6.7689\n","Epoch 277/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6704 - loss: 1.3160 - val_accuracy: 0.4307 - val_loss: 6.7017\n","Epoch 278/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6595 - loss: 1.3538 - val_accuracy: 0.4386 - val_loss: 6.6625\n","Epoch 279/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6639 - loss: 1.3533 - val_accuracy: 0.4298 - val_loss: 6.6733\n","Epoch 280/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6532 - loss: 1.3809 - val_accuracy: 0.4310 - val_loss: 6.7861\n","Epoch 281/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6581 - loss: 1.3634 - val_accuracy: 0.4292 - val_loss: 6.7184\n","Epoch 282/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6649 - loss: 1.3360 - val_accuracy: 0.4336 - val_loss: 6.6636\n","Epoch 283/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6651 - loss: 1.3256 - val_accuracy: 0.4301 - val_loss: 6.6084\n","Epoch 284/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6685 - loss: 1.3097 - val_accuracy: 0.4278 - val_loss: 6.7991\n","Epoch 285/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6631 - loss: 1.3422 - val_accuracy: 0.4291 - val_loss: 6.8103\n","Epoch 286/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6593 - loss: 1.3536 - val_accuracy: 0.4332 - val_loss: 6.7271\n","Epoch 287/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6625 - loss: 1.3332 - val_accuracy: 0.4378 - val_loss: 6.7158\n","Epoch 288/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6592 - loss: 1.3487 - val_accuracy: 0.4276 - val_loss: 6.7750\n","Epoch 289/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6724 - loss: 1.2888 - val_accuracy: 0.4318 - val_loss: 6.8212\n","Epoch 290/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6666 - loss: 1.3210 - val_accuracy: 0.4350 - val_loss: 6.7470\n","Epoch 291/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6771 - loss: 1.2823 - val_accuracy: 0.4344 - val_loss: 6.7249\n","Epoch 292/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6733 - loss: 1.2820 - val_accuracy: 0.4294 - val_loss: 6.7979\n","Epoch 293/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.6616 - loss: 1.3308 - val_accuracy: 0.4297 - val_loss: 6.8404\n","Epoch 294/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6621 - loss: 1.3514 - val_accuracy: 0.4285 - val_loss: 6.7708\n","Epoch 295/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6637 - loss: 1.3355 - val_accuracy: 0.4295 - val_loss: 6.6528\n","Epoch 296/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6689 - loss: 1.3128 - val_accuracy: 0.4330 - val_loss: 6.7456\n","Epoch 297/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6715 - loss: 1.2952 - val_accuracy: 0.4273 - val_loss: 6.8081\n","Epoch 298/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6660 - loss: 1.3134 - val_accuracy: 0.4300 - val_loss: 6.8520\n","Epoch 299/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6641 - loss: 1.3216 - val_accuracy: 0.4326 - val_loss: 6.7893\n","Epoch 300/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6700 - loss: 1.2982 - val_accuracy: 0.4370 - val_loss: 6.7869\n","Epoch 301/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6807 - loss: 1.2510 - val_accuracy: 0.4274 - val_loss: 6.8565\n","Epoch 302/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6588 - loss: 1.3276 - val_accuracy: 0.4287 - val_loss: 6.9266\n","Epoch 303/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6706 - loss: 1.2882 - val_accuracy: 0.4291 - val_loss: 6.7991\n","Epoch 304/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6672 - loss: 1.3027 - val_accuracy: 0.4353 - val_loss: 6.7680\n","Epoch 305/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6691 - loss: 1.2962 - val_accuracy: 0.4293 - val_loss: 6.7077\n","Epoch 306/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6669 - loss: 1.3019 - val_accuracy: 0.4357 - val_loss: 6.8669\n","Epoch 307/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6624 - loss: 1.3287 - val_accuracy: 0.4292 - val_loss: 6.7990\n","Epoch 308/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6725 - loss: 1.2820 - val_accuracy: 0.4320 - val_loss: 6.7024\n","Epoch 309/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6802 - loss: 1.2552 - val_accuracy: 0.4313 - val_loss: 6.7737\n","Epoch 310/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6771 - loss: 1.2584 - val_accuracy: 0.4279 - val_loss: 6.8501\n","Epoch 311/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6699 - loss: 1.2915 - val_accuracy: 0.4261 - val_loss: 6.9245\n","Epoch 312/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6625 - loss: 1.3101 - val_accuracy: 0.4336 - val_loss: 6.8137\n","Epoch 313/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6673 - loss: 1.2946 - val_accuracy: 0.4328 - val_loss: 6.7107\n","Epoch 314/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6826 - loss: 1.2370 - val_accuracy: 0.4260 - val_loss: 6.9690\n","Epoch 315/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6710 - loss: 1.2815 - val_accuracy: 0.4293 - val_loss: 6.8701\n","Epoch 316/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6694 - loss: 1.2829 - val_accuracy: 0.4303 - val_loss: 6.8915\n","Epoch 317/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6675 - loss: 1.2903 - val_accuracy: 0.4322 - val_loss: 6.7978\n","Epoch 318/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6822 - loss: 1.2274 - val_accuracy: 0.4297 - val_loss: 6.8234\n","Epoch 319/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6733 - loss: 1.2638 - val_accuracy: 0.4287 - val_loss: 6.9415\n","Epoch 320/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6787 - loss: 1.2528 - val_accuracy: 0.4309 - val_loss: 6.8489\n","Epoch 321/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6756 - loss: 1.2672 - val_accuracy: 0.4316 - val_loss: 6.7603\n","Epoch 322/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6737 - loss: 1.2632 - val_accuracy: 0.4321 - val_loss: 6.8608\n","Epoch 323/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6693 - loss: 1.2859 - val_accuracy: 0.4271 - val_loss: 6.9102\n","Epoch 324/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6767 - loss: 1.2518 - val_accuracy: 0.4276 - val_loss: 6.9020\n","Epoch 325/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6725 - loss: 1.2703 - val_accuracy: 0.4346 - val_loss: 6.8080\n","Epoch 326/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6744 - loss: 1.2545 - val_accuracy: 0.4330 - val_loss: 6.8181\n","Epoch 327/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6758 - loss: 1.2515 - val_accuracy: 0.4269 - val_loss: 6.8493\n","Epoch 328/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6687 - loss: 1.2858 - val_accuracy: 0.4297 - val_loss: 6.9284\n","Epoch 329/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6764 - loss: 1.2597 - val_accuracy: 0.4280 - val_loss: 6.8591\n","Epoch 330/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6805 - loss: 1.2419 - val_accuracy: 0.4350 - val_loss: 6.9013\n","Epoch 331/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6795 - loss: 1.2413 - val_accuracy: 0.4301 - val_loss: 6.9152\n","Epoch 332/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6796 - loss: 1.2386 - val_accuracy: 0.4301 - val_loss: 6.9230\n","Epoch 333/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6758 - loss: 1.2526 - val_accuracy: 0.4282 - val_loss: 6.9490\n","Epoch 334/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6740 - loss: 1.2486 - val_accuracy: 0.4297 - val_loss: 6.8265\n","Epoch 335/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6783 - loss: 1.2427 - val_accuracy: 0.4292 - val_loss: 6.8982\n","Epoch 336/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6855 - loss: 1.2112 - val_accuracy: 0.4258 - val_loss: 6.9295\n","Epoch 337/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6827 - loss: 1.2156 - val_accuracy: 0.4265 - val_loss: 6.9645\n","Epoch 338/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6881 - loss: 1.1963 - val_accuracy: 0.4336 - val_loss: 6.8590\n","Epoch 339/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6800 - loss: 1.2274 - val_accuracy: 0.4330 - val_loss: 6.8786\n","Epoch 340/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6820 - loss: 1.2176 - val_accuracy: 0.4271 - val_loss: 6.9966\n","Epoch 341/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6730 - loss: 1.2626 - val_accuracy: 0.4281 - val_loss: 6.9105\n","Epoch 342/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6794 - loss: 1.2401 - val_accuracy: 0.4312 - val_loss: 6.8664\n","Epoch 343/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6809 - loss: 1.2204 - val_accuracy: 0.4344 - val_loss: 6.9209\n","Epoch 344/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6831 - loss: 1.2061 - val_accuracy: 0.4258 - val_loss: 6.8718\n","Epoch 345/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6787 - loss: 1.2347 - val_accuracy: 0.4325 - val_loss: 6.9815\n","Epoch 346/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6793 - loss: 1.2323 - val_accuracy: 0.4297 - val_loss: 7.0095\n","Epoch 347/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6809 - loss: 1.2303 - val_accuracy: 0.4323 - val_loss: 6.8876\n","Epoch 348/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6853 - loss: 1.2040 - val_accuracy: 0.4316 - val_loss: 6.8662\n","Epoch 349/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6802 - loss: 1.2202 - val_accuracy: 0.4229 - val_loss: 6.9756\n","Epoch 350/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6820 - loss: 1.2161 - val_accuracy: 0.4262 - val_loss: 7.0520\n","Epoch 351/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6791 - loss: 1.2308 - val_accuracy: 0.4338 - val_loss: 6.9680\n","Epoch 352/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6879 - loss: 1.2046 - val_accuracy: 0.4304 - val_loss: 6.9163\n","Epoch 353/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6717 - loss: 1.2602 - val_accuracy: 0.4251 - val_loss: 7.0357\n","Epoch 354/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6817 - loss: 1.2248 - val_accuracy: 0.4311 - val_loss: 7.0594\n","Epoch 355/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6798 - loss: 1.2271 - val_accuracy: 0.4312 - val_loss: 6.9687\n","Epoch 356/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6950 - loss: 1.1740 - val_accuracy: 0.4336 - val_loss: 6.9367\n","Epoch 357/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6766 - loss: 1.2449 - val_accuracy: 0.4285 - val_loss: 6.8988\n","Epoch 358/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6656 - loss: 1.2693 - val_accuracy: 0.4302 - val_loss: 7.0222\n","Epoch 359/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6812 - loss: 1.2077 - val_accuracy: 0.4252 - val_loss: 7.0103\n","Epoch 360/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6708 - loss: 1.2714 - val_accuracy: 0.4297 - val_loss: 6.9364\n","Epoch 361/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6852 - loss: 1.2053 - val_accuracy: 0.4282 - val_loss: 6.9710\n","Epoch 362/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6863 - loss: 1.1872 - val_accuracy: 0.4263 - val_loss: 7.0483\n","Epoch 363/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6882 - loss: 1.1840 - val_accuracy: 0.4295 - val_loss: 7.0591\n","Epoch 364/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6753 - loss: 1.2523 - val_accuracy: 0.4350 - val_loss: 6.9040\n","Epoch 365/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6887 - loss: 1.1870 - val_accuracy: 0.4367 - val_loss: 7.0451\n","Epoch 366/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6739 - loss: 1.2500 - val_accuracy: 0.4294 - val_loss: 6.9317\n","Epoch 367/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6785 - loss: 1.2296 - val_accuracy: 0.4244 - val_loss: 7.0789\n","Epoch 368/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6845 - loss: 1.1934 - val_accuracy: 0.4271 - val_loss: 7.0089\n","Epoch 369/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6768 - loss: 1.2250 - val_accuracy: 0.4364 - val_loss: 6.9589\n","Epoch 370/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6875 - loss: 1.1832 - val_accuracy: 0.4295 - val_loss: 6.9076\n","Epoch 371/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6772 - loss: 1.2247 - val_accuracy: 0.4301 - val_loss: 7.0649\n","Epoch 372/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6884 - loss: 1.1983 - val_accuracy: 0.4290 - val_loss: 7.0291\n","Epoch 373/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6793 - loss: 1.2170 - val_accuracy: 0.4319 - val_loss: 6.9489\n","Epoch 374/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6828 - loss: 1.2054 - val_accuracy: 0.4288 - val_loss: 6.9965\n","Epoch 375/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6795 - loss: 1.2203 - val_accuracy: 0.4242 - val_loss: 7.0904\n","Epoch 376/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6851 - loss: 1.1926 - val_accuracy: 0.4275 - val_loss: 7.1164\n","Epoch 377/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6857 - loss: 1.1892 - val_accuracy: 0.4343 - val_loss: 7.0305\n","Epoch 378/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6788 - loss: 1.2173 - val_accuracy: 0.4328 - val_loss: 7.0083\n","Epoch 379/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6814 - loss: 1.2018 - val_accuracy: 0.4237 - val_loss: 7.1437\n","Epoch 380/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6655 - loss: 1.2611 - val_accuracy: 0.4267 - val_loss: 7.1210\n","Epoch 381/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6826 - loss: 1.1987 - val_accuracy: 0.4305 - val_loss: 7.0626\n","Epoch 382/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6808 - loss: 1.2100 - val_accuracy: 0.4336 - val_loss: 7.0947\n","Epoch 383/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6769 - loss: 1.2184 - val_accuracy: 0.4263 - val_loss: 6.9984\n","Epoch 384/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6786 - loss: 1.2201 - val_accuracy: 0.4286 - val_loss: 7.1653\n","Epoch 385/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6740 - loss: 1.2379 - val_accuracy: 0.4283 - val_loss: 7.1200\n","Epoch 386/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6833 - loss: 1.1979 - val_accuracy: 0.4284 - val_loss: 6.9182\n","Epoch 387/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6861 - loss: 1.1957 - val_accuracy: 0.4309 - val_loss: 7.0522\n","Epoch 388/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6806 - loss: 1.2089 - val_accuracy: 0.4247 - val_loss: 7.1215\n","Epoch 389/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6911 - loss: 1.1609 - val_accuracy: 0.4315 - val_loss: 7.1602\n","Epoch 390/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6864 - loss: 1.1748 - val_accuracy: 0.4334 - val_loss: 7.0723\n","Epoch 391/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6816 - loss: 1.2042 - val_accuracy: 0.4328 - val_loss: 7.0668\n","Epoch 392/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6884 - loss: 1.1668 - val_accuracy: 0.4274 - val_loss: 7.1263\n","Epoch 393/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6796 - loss: 1.2030 - val_accuracy: 0.4296 - val_loss: 7.1890\n","Epoch 394/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6931 - loss: 1.1514 - val_accuracy: 0.4329 - val_loss: 7.1578\n","Epoch 395/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6926 - loss: 1.1722 - val_accuracy: 0.4318 - val_loss: 7.1294\n","Epoch 396/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6782 - loss: 1.2178 - val_accuracy: 0.4282 - val_loss: 7.1002\n","Epoch 397/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6842 - loss: 1.1907 - val_accuracy: 0.4313 - val_loss: 7.1843\n","Epoch 398/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6833 - loss: 1.1888 - val_accuracy: 0.4241 - val_loss: 7.1728\n","Epoch 399/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6933 - loss: 1.1598 - val_accuracy: 0.4279 - val_loss: 7.0645\n","Epoch 400/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6871 - loss: 1.1797 - val_accuracy: 0.4259 - val_loss: 7.0961\n","Epoch 401/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.6894 - loss: 1.1750 - val_accuracy: 0.4223 - val_loss: 7.1530\n","Epoch 402/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6809 - loss: 1.1988 - val_accuracy: 0.4245 - val_loss: 7.2270\n","Epoch 403/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - accuracy: 0.6877 - loss: 1.1664 - val_accuracy: 0.4320 - val_loss: 7.0661\n","Epoch 404/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.6835 - loss: 1.1911 - val_accuracy: 0.4330 - val_loss: 7.1563\n","Epoch 405/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6868 - loss: 1.1795 - val_accuracy: 0.4258 - val_loss: 7.2390\n","Epoch 406/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6878 - loss: 1.1690 - val_accuracy: 0.4202 - val_loss: 7.2241\n","Epoch 407/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.6785 - loss: 1.2038 - val_accuracy: 0.4230 - val_loss: 7.1509\n","Epoch 408/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6843 - loss: 1.1816 - val_accuracy: 0.4325 - val_loss: 7.0050\n","Epoch 409/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6881 - loss: 1.1645 - val_accuracy: 0.4259 - val_loss: 7.0450\n","Epoch 410/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6878 - loss: 1.1720 - val_accuracy: 0.4244 - val_loss: 7.1944\n","Epoch 411/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6970 - loss: 1.1365 - val_accuracy: 0.4264 - val_loss: 7.1509\n","Epoch 412/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6937 - loss: 1.1473 - val_accuracy: 0.4290 - val_loss: 7.1140\n","Epoch 413/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.6880 - loss: 1.1687 - val_accuracy: 0.4326 - val_loss: 7.1151\n","Epoch 414/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6800 - loss: 1.1838 - val_accuracy: 0.4237 - val_loss: 7.2145\n","Epoch 415/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6959 - loss: 1.1356 - val_accuracy: 0.4265 - val_loss: 7.2913\n","Epoch 416/2000\n","\u001b[1m 19/112\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 2s/step - accuracy: 0.6627 - loss: 1.2465"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","import string\n","import re\n","import unicodedata\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import Callback\n","# Load data\n","data = pd.read_csv(\"chat_health.csv\")\n","data = data.head(2000)\n","\n","# Define function to convert unicode to ASCII\n","def unicode_to_ascii(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                   if unicodedata.category(c) != 'Mn')\n","\n","# Define text cleaning function\n","def clean_text(text):\n","    text = unicode_to_ascii(text.lower().strip())\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\"\\r\", \"\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"what's\", \"that is\", text)\n","    text = re.sub(r\"where's\", \"where is\", text)\n","    text = re.sub(r\"how's\", \"how is\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'ve\", \" have\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"\\'d\", \" would\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"n't\", \" not\", text)\n","    text = re.sub(r\"n'\", \"ng\", text)\n","    text = re.sub(r\"'bout\", \"about\", text)\n","    text = re.sub(r\"'til\", \"until\", text)\n","    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    text = re.sub(\"(\\\\W)\",\" \",text)\n","    text = re.sub('\\S*\\d\\S*\\s*','', text)\n","    return text\n","\n","data[\"short_question\"] = data.short_question.apply(clean_text)\n","data[\"short_answer\"] = data.short_answer.apply(clean_text)\n","\n","# Text preprocessing\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(data['short_question'].tolist() + data['short_answer'].tolist())\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","questions_seq = tokenizer.texts_to_sequences(data['short_question'])\n","answers_seq = tokenizer.texts_to_sequences(data['short_answer'])\n","\n","max_length = max(max(len(x) for x in questions_seq), max(len(x) for x in answers_seq))\n","questions_padded = pad_sequences(questions_seq, maxlen=max_length, padding='post')\n","answers_padded = pad_sequences(answers_seq, maxlen=max_length, padding='post')\n","\n","# Split dataset\n","train_questions, val_questions, train_answers, val_answers = train_test_split(\n","    questions_padded, answers_padded, test_size=0.1, random_state=42)\n","\n","# Prepare training and validation datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_questions, train_answers))\n","train_dataset = train_dataset.shuffle(buffer_size=10000).batch(16).repeat()\n","\n","val_dataset = tf.data.Dataset.from_tensor_slices((val_questions, val_answers))\n","val_dataset = val_dataset.batch(16).repeat()\n","\n","# Build model\n","model = Sequential([\n","    Embedding(vocab_size, 128),\n","    Bidirectional(LSTM(256, return_sequences=True)),\n","    Dropout(0.5),\n","    BatchNormalization(),\n","    Bidirectional(LSTM(256, return_sequences=True)),\n","    Dropout(0.5),\n","    Dense(vocab_size, activation='softmax')\n","])\n","\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Adjust batch_size or directly use the entire dataset\n","batch_size = 16\n","class CombinedStoppingCallback(Callback):\n","    def __init__(self, loss_threshold=0.01, improvement_threshold=0.01, patience=200):\n","        super(CombinedStoppingCallback, self).__init__()\n","        self.loss_threshold = loss_threshold  # Stop training if loss is below this value\n","        self.improvement_threshold = improvement_threshold  # Consider stopping if improvement is less than this value\n","        self.patience = patience  # Max consecutive epochs to wait before deciding to stop\n","        self.best_loss = float('inf')\n","        self.best_epoch = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_loss = logs.get('loss')\n","        if current_loss is None:\n","            return\n","\n","        # Check if the loss has reached below the threshold\n","        if current_loss < self.loss_threshold:\n","            print(f\"\\nEpoch {epoch}: Stopping training as loss {current_loss} is below threshold {self.loss_threshold}.\")\n","            self.model.stop_training = True\n","\n","        # Check if there is a significant improvement in loss\n","        if current_loss < self.best_loss:\n","            self.best_loss = current_loss\n","            self.best_epoch = epoch\n","        else:\n","            # Check if it has been 'patience' epochs since the last best loss and the improvement is not enough\n","            if (epoch - self.best_epoch) >= self.patience and (self.best_loss - current_loss) < self.improvement_threshold:\n","                print(f\"\\nEpoch {epoch}: No significant improvement in loss for {self.patience} epochs. Stopping training.\")\n","                self.model.stop_training = True\n","\n","# Create an instance of CombinedStoppingCallback\n","stopping_callback = CombinedStoppingCallback(loss_threshold=0.1, improvement_threshold=0.1, patience=30)\n","\n","# Use the model and save training history\n","history = model.fit(\n","    train_dataset,\n","    epochs=2000,\n","    steps_per_epoch=max(1, len(train_questions) // batch_size),\n","    validation_data=val_dataset,\n","    validation_steps=max(1, len(val_questions) // batch_size),\n","    callbacks=[stopping_callback]\n",")"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"qP6Z_BbTnia-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_weights('GRU_2000.weights.h5')\n","\n","\n","# save Tokenizer\n","import pickle\n","with open('tokenizer_GRU_2000.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"nnO3Bi2qBZpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download('GRU_2000.weights.h5')\n","files.download('tokenizer_GRU_2000.pickle')"],"metadata":{"id":"V-zLvaJoFUSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size"],"metadata":{"id":"ER-9V-67q-b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length"],"metadata":{"id":"RmfHdA5uswoE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","import pickle\n","\n","\n","model1  = Sequential([\n","    Embedding(vocab_size, 128),\n","    Bidirectional(LSTM(256, return_sequences=True)),\n","    Dropout(0.5),\n","    BatchNormalization(),\n","    Bidirectional(LSTM(256, return_sequences=True)),\n","    Dropout(0.5),\n","    Dense(vocab_size, activation='softmax')\n","])\n","\n","model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","model1.build(input_shape=(None, max_length))\n","\n","model1.load_weights('my_model_weights.weights.h5')\n","model1.summary()"],"metadata":{"id":"v39XrjQhMqcF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dGjYUTxiHEo-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate answer\n","def generate_answer(question,model):\n","    question_seq = tokenizer.texts_to_sequences([question])\n","    question_padded = pad_sequences(question_seq, maxlen=max_length, padding='post')\n","    prediction = model.predict(question_padded)\n","    predicted_indices = np.argmax(prediction, axis=-1)[0]\n","    predicted_words = ' '.join([tokenizer.index_word[i] for i in predicted_indices if i != 0])\n","    return predicted_words"],"metadata":{"id":"-deuvQX_PS-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testData = pd.read_csv('chat_health.csv').head(50)"],"metadata":{"id":"KYj5maPcP8ii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu\n","testData['generated_answer'] = testData['short_question'].apply(lambda q: generate_answer(q, model1))\n","\n","references = testData['short_answer'].apply(lambda a: [a.split()]).tolist()\n","candidates = testData['generated_answer'].apply(lambda a: a.split()).tolist()\n","\n","bleu_score = corpus_bleu(references, candidates)\n","print(\"BLEU Score:\", bleu_score)"],"metadata":{"id":"mzu4S6LDPz5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","start_time = time.time()\n","testData['generated_answer'] = testData['short_question'].head(50).apply(lambda q: generate_answer(q, model1))\n","end_time = time.time()\n","response_time = end_time - start_time\n","average_response_time = response_time / 50\n","\n","print(f\"Average response time per record: {average_response_time} seconds\")"],"metadata":{"id":"_P12RjplD2-1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"X4vD3gJQ_Tr4"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# Plotting loss curves\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Loss Curves')\n","plt.show()\n","\n","# Plotting accuracy curves\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Learning Curves')\n","plt.show()"],"metadata":{"id":"U3rBP4re9zm8"},"execution_count":null,"outputs":[]}]}