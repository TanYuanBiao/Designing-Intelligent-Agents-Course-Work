{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1h0sqICnxL76V4zGHqY-4SjhcikYsMzfQ","timestamp":1715353499001}],"authorship_tag":"ABX9TyO+RdAaBWxgfTxfa7/0JSbd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tensorflow==2.16.1\n","!pip install keras==3.1.1"],"metadata":{"id":"mBhcnJLKgT3A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715353645272,"user_tz":-60,"elapsed":99849,"user":{"displayName":"by tan","userId":"09012215015310927543"}},"outputId":"c6975a5a-8f2b-4c23-f744-4c927e618b98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.16.1\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow==2.16.1)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.63.0)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras>=3.0.0 (from tensorflow==2.16.1)\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.7.1)\n","Collecting namex (from keras>=3.0.0->tensorflow==2.16.1)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras>=3.0.0->tensorflow==2.16.1)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n","Collecting keras==3.1.1\n","  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (1.25.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.11.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras==3.1.1) (0.3.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras==3.1.1) (4.11.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.1.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.1.1) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.1.1) (0.1.2)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.3.3\n","    Uninstalling keras-3.3.3:\n","      Successfully uninstalled keras-3.3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.1.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqFAjv2EYe8V","outputId":"eee78f01-84b1-41cd-8928-f7073b03e93c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 1s/step - accuracy: 0.4597 - loss: 5.1581 - val_accuracy: 0.5034 - val_loss: 4.0792\n","Epoch 2/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5208 - loss: 3.6227 - val_accuracy: 0.5009 - val_loss: 3.8926\n","Epoch 3/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5164 - loss: 3.6170 - val_accuracy: 0.5010 - val_loss: 3.8380\n","Epoch 4/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5320 - loss: 3.4931 - val_accuracy: 0.5046 - val_loss: 3.8539\n","Epoch 5/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.5173 - loss: 3.5264 - val_accuracy: 0.5089 - val_loss: 3.8326\n","Epoch 6/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.5309 - loss: 3.4101 - val_accuracy: 0.5061 - val_loss: 3.9118\n","Epoch 7/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.5330 - loss: 3.3672 - val_accuracy: 0.4995 - val_loss: 3.9198\n","Epoch 8/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5198 - loss: 3.4417 - val_accuracy: 0.5003 - val_loss: 4.0347\n","Epoch 9/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5343 - loss: 3.3365 - val_accuracy: 0.5055 - val_loss: 4.0150\n","Epoch 10/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5262 - loss: 3.3385 - val_accuracy: 0.4945 - val_loss: 4.0623\n","Epoch 11/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5188 - loss: 3.3461 - val_accuracy: 0.4812 - val_loss: 4.1079\n","Epoch 12/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5328 - loss: 3.2281 - val_accuracy: 0.4979 - val_loss: 4.0355\n","Epoch 13/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5295 - loss: 3.2235 - val_accuracy: 0.4974 - val_loss: 4.0596\n","Epoch 14/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5338 - loss: 3.1803 - val_accuracy: 0.4949 - val_loss: 4.1099\n","Epoch 15/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5219 - loss: 3.2263 - val_accuracy: 0.3312 - val_loss: 5.1454\n","Epoch 16/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5451 - loss: 3.0227 - val_accuracy: 0.4907 - val_loss: 4.1597\n","Epoch 17/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5225 - loss: 3.1543 - val_accuracy: 0.4893 - val_loss: 4.1698\n","Epoch 18/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5277 - loss: 3.0950 - val_accuracy: 0.5005 - val_loss: 4.1499\n","Epoch 19/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5300 - loss: 3.0320 - val_accuracy: 0.4940 - val_loss: 4.2297\n","Epoch 20/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5327 - loss: 2.9919 - val_accuracy: 0.4711 - val_loss: 4.3157\n","Epoch 21/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5363 - loss: 2.9366 - val_accuracy: 0.4815 - val_loss: 4.2638\n","Epoch 22/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5313 - loss: 2.9367 - val_accuracy: 0.4812 - val_loss: 4.2675\n","Epoch 23/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5380 - loss: 2.8673 - val_accuracy: 0.4767 - val_loss: 4.3496\n","Epoch 24/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5470 - loss: 2.7708 - val_accuracy: 0.4698 - val_loss: 4.3812\n","Epoch 25/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5334 - loss: 2.8463 - val_accuracy: 0.4659 - val_loss: 4.4291\n","Epoch 26/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5315 - loss: 2.8216 - val_accuracy: 0.4789 - val_loss: 4.3443\n","Epoch 27/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5337 - loss: 2.7929 - val_accuracy: 0.4766 - val_loss: 4.3549\n","Epoch 28/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5395 - loss: 2.7290 - val_accuracy: 0.4733 - val_loss: 4.4168\n","Epoch 29/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5576 - loss: 2.6062 - val_accuracy: 0.4781 - val_loss: 4.4123\n","Epoch 30/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.5403 - loss: 2.6743 - val_accuracy: 0.4835 - val_loss: 4.4927\n","Epoch 31/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.5505 - loss: 2.6089 - val_accuracy: 0.4718 - val_loss: 4.4749\n","Epoch 32/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.5449 - loss: 2.6129 - val_accuracy: 0.4763 - val_loss: 4.4445\n","Epoch 33/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - accuracy: 0.5454 - loss: 2.5850 - val_accuracy: 0.4597 - val_loss: 4.5191\n","Epoch 34/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.5524 - loss: 2.5326 - val_accuracy: 0.4782 - val_loss: 4.6612\n","Epoch 35/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5535 - loss: 2.5235 - val_accuracy: 0.4906 - val_loss: 4.5729\n","Epoch 36/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.5488 - loss: 2.5184 - val_accuracy: 0.4704 - val_loss: 4.5715\n","Epoch 37/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5490 - loss: 2.5189 - val_accuracy: 0.4715 - val_loss: 4.5843\n","Epoch 38/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5526 - loss: 2.4813 - val_accuracy: 0.4703 - val_loss: 4.5593\n","Epoch 39/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5526 - loss: 2.4598 - val_accuracy: 0.4648 - val_loss: 4.5570\n","Epoch 40/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5454 - loss: 2.4940 - val_accuracy: 0.4761 - val_loss: 4.6326\n","Epoch 41/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5565 - loss: 2.4375 - val_accuracy: 0.4505 - val_loss: 4.7217\n","Epoch 42/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.5444 - loss: 2.4685 - val_accuracy: 0.4656 - val_loss: 4.7309\n","Epoch 43/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5534 - loss: 2.4324 - val_accuracy: 0.4611 - val_loss: 4.6517\n","Epoch 44/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.5601 - loss: 2.3795 - val_accuracy: 0.4720 - val_loss: 4.6001\n","Epoch 45/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5544 - loss: 2.3948 - val_accuracy: 0.4629 - val_loss: 4.6261\n","Epoch 46/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5569 - loss: 2.3849 - val_accuracy: 0.4495 - val_loss: 4.7288\n","Epoch 47/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.5485 - loss: 2.4038 - val_accuracy: 0.4587 - val_loss: 4.6630\n","Epoch 48/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.5654 - loss: 2.3070 - val_accuracy: 0.4625 - val_loss: 4.6558\n","Epoch 49/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5552 - loss: 2.3569 - val_accuracy: 0.4406 - val_loss: 4.7571\n","Epoch 50/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.5441 - loss: 2.4084 - val_accuracy: 0.4597 - val_loss: 4.8686\n","Epoch 51/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 2.3061 - val_accuracy: 0.4581 - val_loss: 4.7247\n","Epoch 52/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5691 - loss: 2.2549 - val_accuracy: 0.4496 - val_loss: 4.7442\n","Epoch 53/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5535 - loss: 2.3273 - val_accuracy: 0.4598 - val_loss: 4.7392\n","Epoch 54/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5599 - loss: 2.2921 - val_accuracy: 0.4511 - val_loss: 4.8198\n","Epoch 55/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5526 - loss: 2.3093 - val_accuracy: 0.4495 - val_loss: 4.8583\n","Epoch 56/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5634 - loss: 2.2627 - val_accuracy: 0.4510 - val_loss: 4.8096\n","Epoch 57/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5640 - loss: 2.2491 - val_accuracy: 0.4627 - val_loss: 4.7634\n","Epoch 58/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5599 - loss: 2.2633 - val_accuracy: 0.4585 - val_loss: 4.7710\n","Epoch 59/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.5776 - loss: 2.1663 - val_accuracy: 0.4563 - val_loss: 4.8900\n","Epoch 60/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5641 - loss: 2.2464 - val_accuracy: 0.4453 - val_loss: 4.8967\n","Epoch 61/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5565 - loss: 2.2759 - val_accuracy: 0.4643 - val_loss: 4.8264\n","Epoch 62/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5662 - loss: 2.2078 - val_accuracy: 0.4616 - val_loss: 4.8928\n","Epoch 63/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5689 - loss: 2.1972 - val_accuracy: 0.4383 - val_loss: 4.8855\n","Epoch 64/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.5696 - loss: 2.1814 - val_accuracy: 0.4423 - val_loss: 4.8957\n","Epoch 65/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.5617 - loss: 2.2074 - val_accuracy: 0.4537 - val_loss: 4.8349\n","Epoch 66/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5646 - loss: 2.2037 - val_accuracy: 0.4550 - val_loss: 4.8318\n","Epoch 67/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5715 - loss: 2.1557 - val_accuracy: 0.4523 - val_loss: 4.9564\n","Epoch 68/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.5726 - loss: 2.1549 - val_accuracy: 0.4491 - val_loss: 4.9965\n","Epoch 69/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.5613 - loss: 2.2026 - val_accuracy: 0.4604 - val_loss: 4.9310\n","Epoch 70/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.5670 - loss: 2.1574 - val_accuracy: 0.4532 - val_loss: 4.8985\n","Epoch 71/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - accuracy: 0.5762 - loss: 2.1216 - val_accuracy: 0.4497 - val_loss: 4.8818\n","Epoch 72/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.5665 - loss: 2.1603 - val_accuracy: 0.4556 - val_loss: 4.9667\n","Epoch 73/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5806 - loss: 2.0834 - val_accuracy: 0.4492 - val_loss: 4.9472\n","Epoch 74/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5734 - loss: 2.1200 - val_accuracy: 0.4503 - val_loss: 4.8843\n","Epoch 75/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5736 - loss: 2.1134 - val_accuracy: 0.4507 - val_loss: 4.9705\n","Epoch 76/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5679 - loss: 2.1291 - val_accuracy: 0.4456 - val_loss: 5.0270\n","Epoch 77/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.5717 - loss: 2.1088 - val_accuracy: 0.4463 - val_loss: 5.0172\n","Epoch 78/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5775 - loss: 2.0781 - val_accuracy: 0.4488 - val_loss: 4.9293\n","Epoch 79/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5649 - loss: 2.1317 - val_accuracy: 0.4577 - val_loss: 4.9818\n","Epoch 80/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.5761 - loss: 2.0717 - val_accuracy: 0.4468 - val_loss: 5.0533\n","Epoch 81/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - accuracy: 0.5741 - loss: 2.0848 - val_accuracy: 0.4448 - val_loss: 5.0603\n","Epoch 82/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.5699 - loss: 2.1017 - val_accuracy: 0.4527 - val_loss: 5.0084\n","Epoch 83/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5764 - loss: 2.0586 - val_accuracy: 0.4490 - val_loss: 5.0268\n","Epoch 84/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 0.5720 - loss: 2.0753 - val_accuracy: 0.4393 - val_loss: 4.9727\n","Epoch 85/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.5786 - loss: 2.0411 - val_accuracy: 0.4473 - val_loss: 5.0398\n","Epoch 86/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.5795 - loss: 2.0386 - val_accuracy: 0.4461 - val_loss: 5.0276\n","Epoch 87/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5697 - loss: 2.0810 - val_accuracy: 0.4512 - val_loss: 4.9830\n","Epoch 88/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.5759 - loss: 2.0429 - val_accuracy: 0.4511 - val_loss: 5.0697\n","Epoch 89/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5850 - loss: 1.9994 - val_accuracy: 0.4441 - val_loss: 5.1060\n","Epoch 90/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5720 - loss: 2.0540 - val_accuracy: 0.4455 - val_loss: 5.1112\n","Epoch 91/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5821 - loss: 2.0118 - val_accuracy: 0.4455 - val_loss: 5.0756\n","Epoch 92/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5827 - loss: 2.0061 - val_accuracy: 0.4517 - val_loss: 4.9823\n","Epoch 93/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5800 - loss: 2.0111 - val_accuracy: 0.4421 - val_loss: 5.0982\n","Epoch 94/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5913 - loss: 1.9485 - val_accuracy: 0.4457 - val_loss: 5.1737\n","Epoch 95/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5744 - loss: 2.0403 - val_accuracy: 0.4433 - val_loss: 5.1021\n","Epoch 96/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5815 - loss: 1.9984 - val_accuracy: 0.4575 - val_loss: 5.0600\n","Epoch 97/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - accuracy: 0.5874 - loss: 1.9526 - val_accuracy: 0.4492 - val_loss: 5.0637\n","Epoch 98/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5817 - loss: 1.9838 - val_accuracy: 0.4389 - val_loss: 5.0542\n","Epoch 99/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.5885 - loss: 1.9438 - val_accuracy: 0.4478 - val_loss: 5.1515\n","Epoch 100/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.5779 - loss: 1.9998 - val_accuracy: 0.4398 - val_loss: 5.0161\n","Epoch 101/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5898 - loss: 1.9274 - val_accuracy: 0.4537 - val_loss: 5.0797\n","Epoch 102/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5840 - loss: 1.9639 - val_accuracy: 0.4449 - val_loss: 5.1253\n","Epoch 103/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5871 - loss: 1.9413 - val_accuracy: 0.4414 - val_loss: 5.1957\n","Epoch 104/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.5838 - loss: 1.9655 - val_accuracy: 0.4506 - val_loss: 5.0438\n","Epoch 105/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5957 - loss: 1.9004 - val_accuracy: 0.4486 - val_loss: 5.1062\n","Epoch 106/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5834 - loss: 1.9596 - val_accuracy: 0.4388 - val_loss: 5.1704\n","Epoch 107/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.5837 - loss: 1.9468 - val_accuracy: 0.4395 - val_loss: 5.1713\n","Epoch 108/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.5954 - loss: 1.8927 - val_accuracy: 0.4466 - val_loss: 5.1439\n","Epoch 109/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5909 - loss: 1.9077 - val_accuracy: 0.4567 - val_loss: 5.1559\n","Epoch 110/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5939 - loss: 1.8991 - val_accuracy: 0.4405 - val_loss: 5.1296\n","Epoch 111/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.5875 - loss: 1.9159 - val_accuracy: 0.4370 - val_loss: 5.1846\n","Epoch 112/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - accuracy: 0.5868 - loss: 1.9179 - val_accuracy: 0.4350 - val_loss: 5.1553\n","Epoch 113/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.5852 - loss: 1.9229 - val_accuracy: 0.4425 - val_loss: 5.1352\n","Epoch 114/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5944 - loss: 1.8733 - val_accuracy: 0.4449 - val_loss: 5.1361\n","Epoch 115/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5940 - loss: 1.8846 - val_accuracy: 0.4425 - val_loss: 5.2457\n","Epoch 116/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.5925 - loss: 1.8891 - val_accuracy: 0.4421 - val_loss: 5.2429\n","Epoch 117/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2s/step - accuracy: 0.5862 - loss: 1.9046 - val_accuracy: 0.4412 - val_loss: 5.1090\n","Epoch 118/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.5949 - loss: 1.8699 - val_accuracy: 0.4441 - val_loss: 5.1318\n","Epoch 119/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.5926 - loss: 1.8746 - val_accuracy: 0.4402 - val_loss: 5.2613\n","Epoch 120/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2s/step - accuracy: 0.5921 - loss: 1.8940 - val_accuracy: 0.4363 - val_loss: 5.2319\n","Epoch 121/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2s/step - accuracy: 0.6000 - loss: 1.8421 - val_accuracy: 0.4464 - val_loss: 5.1837\n","Epoch 122/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 2s/step - accuracy: 0.5957 - loss: 1.8659 - val_accuracy: 0.4531 - val_loss: 5.1641\n","Epoch 123/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - accuracy: 0.5982 - loss: 1.8586 - val_accuracy: 0.4424 - val_loss: 5.1333\n","Epoch 124/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.5901 - loss: 1.8849 - val_accuracy: 0.4463 - val_loss: 5.2411\n","Epoch 125/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.5805 - loss: 1.9284 - val_accuracy: 0.4413 - val_loss: 5.1986\n","Epoch 126/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 2s/step - accuracy: 0.5974 - loss: 1.8425 - val_accuracy: 0.4425 - val_loss: 5.1504\n","Epoch 127/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 2s/step - accuracy: 0.5851 - loss: 1.9031 - val_accuracy: 0.4415 - val_loss: 5.2141\n","Epoch 128/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.5855 - loss: 1.9054 - val_accuracy: 0.4375 - val_loss: 5.2466\n","Epoch 129/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.5885 - loss: 1.8984 - val_accuracy: 0.4374 - val_loss: 5.2786\n","Epoch 130/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6094 - loss: 1.7910 - val_accuracy: 0.4426 - val_loss: 5.2164\n","Epoch 131/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5951 - loss: 1.8646 - val_accuracy: 0.4441 - val_loss: 5.2055\n","Epoch 132/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5743 - loss: 1.9593 - val_accuracy: 0.4380 - val_loss: 5.3098\n","Epoch 133/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.5879 - loss: 1.8725 - val_accuracy: 0.4358 - val_loss: 5.3088\n","Epoch 134/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.5897 - loss: 1.8798 - val_accuracy: 0.4384 - val_loss: 5.2833\n","Epoch 135/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6033 - loss: 1.8124 - val_accuracy: 0.4402 - val_loss: 5.2044\n","Epoch 136/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.5904 - loss: 1.8740 - val_accuracy: 0.4420 - val_loss: 5.2771\n","Epoch 137/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6010 - loss: 1.8164 - val_accuracy: 0.4408 - val_loss: 5.3004\n","Epoch 138/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.5943 - loss: 1.8522 - val_accuracy: 0.4402 - val_loss: 5.2984\n","Epoch 139/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.5884 - loss: 1.8741 - val_accuracy: 0.4465 - val_loss: 5.2443\n","Epoch 140/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.5882 - loss: 1.8724 - val_accuracy: 0.4439 - val_loss: 5.2789\n","Epoch 141/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 0.5840 - loss: 1.8770 - val_accuracy: 0.4400 - val_loss: 5.3371\n","Epoch 142/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6041 - loss: 1.7768 - val_accuracy: 0.4408 - val_loss: 5.3894\n","Epoch 143/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6007 - loss: 1.8152 - val_accuracy: 0.4392 - val_loss: 5.2751\n","Epoch 144/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5961 - loss: 1.8277 - val_accuracy: 0.4426 - val_loss: 5.2576\n","Epoch 145/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5878 - loss: 1.8680 - val_accuracy: 0.4329 - val_loss: 5.3735\n","Epoch 146/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6016 - loss: 1.8088 - val_accuracy: 0.4415 - val_loss: 5.4095\n","Epoch 147/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.5989 - loss: 1.8081 - val_accuracy: 0.4450 - val_loss: 5.3484\n","Epoch 148/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.5976 - loss: 1.8119 - val_accuracy: 0.4492 - val_loss: 5.2782\n","Epoch 149/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - accuracy: 0.5881 - loss: 1.8637 - val_accuracy: 0.4381 - val_loss: 5.2324\n","Epoch 150/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5921 - loss: 1.8407 - val_accuracy: 0.4351 - val_loss: 5.3444\n","Epoch 151/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.5921 - loss: 1.8395 - val_accuracy: 0.4388 - val_loss: 5.3227\n","Epoch 152/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5949 - loss: 1.8305 - val_accuracy: 0.4391 - val_loss: 5.3027\n","Epoch 153/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5957 - loss: 1.8133 - val_accuracy: 0.4407 - val_loss: 5.2836\n","Epoch 154/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6011 - loss: 1.7844 - val_accuracy: 0.4402 - val_loss: 5.3907\n","Epoch 155/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5994 - loss: 1.8042 - val_accuracy: 0.4346 - val_loss: 5.3474\n","Epoch 156/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.5988 - loss: 1.8101 - val_accuracy: 0.4449 - val_loss: 5.3245\n","Epoch 157/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.5893 - loss: 1.8267 - val_accuracy: 0.4338 - val_loss: 5.3501\n","Epoch 158/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6017 - loss: 1.7860 - val_accuracy: 0.4291 - val_loss: 5.3605\n","Epoch 159/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6010 - loss: 1.7721 - val_accuracy: 0.4375 - val_loss: 5.4256\n","Epoch 160/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.5999 - loss: 1.7858 - val_accuracy: 0.4421 - val_loss: 5.3258\n","Epoch 161/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6008 - loss: 1.7768 - val_accuracy: 0.4514 - val_loss: 5.2998\n","Epoch 162/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 2s/step - accuracy: 0.6053 - loss: 1.7652 - val_accuracy: 0.4366 - val_loss: 5.3126\n","Epoch 163/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.5949 - loss: 1.8096 - val_accuracy: 0.4392 - val_loss: 5.3402\n","Epoch 164/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.6106 - loss: 1.7472 - val_accuracy: 0.4421 - val_loss: 5.3453\n","Epoch 165/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2s/step - accuracy: 0.6042 - loss: 1.7769 - val_accuracy: 0.4460 - val_loss: 5.3463\n","Epoch 166/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5909 - loss: 1.8066 - val_accuracy: 0.4421 - val_loss: 5.4181\n","Epoch 167/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - accuracy: 0.6074 - loss: 1.7515 - val_accuracy: 0.4275 - val_loss: 5.4004\n","Epoch 168/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.5996 - loss: 1.7842 - val_accuracy: 0.4336 - val_loss: 5.4080\n","Epoch 169/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.6055 - loss: 1.7434 - val_accuracy: 0.4405 - val_loss: 5.3756\n","Epoch 170/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step - accuracy: 0.6109 - loss: 1.7190 - val_accuracy: 0.4454 - val_loss: 5.3444\n","Epoch 171/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.6072 - loss: 1.7413 - val_accuracy: 0.4328 - val_loss: 5.4518\n","Epoch 172/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.6014 - loss: 1.7663 - val_accuracy: 0.4375 - val_loss: 5.5056\n","Epoch 173/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6018 - loss: 1.7673 - val_accuracy: 0.4350 - val_loss: 5.3911\n","Epoch 174/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.5979 - loss: 1.7821 - val_accuracy: 0.4425 - val_loss: 5.3242\n","Epoch 175/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6019 - loss: 1.7656 - val_accuracy: 0.4358 - val_loss: 5.3536\n","Epoch 176/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6036 - loss: 1.7449 - val_accuracy: 0.4384 - val_loss: 5.4728\n","Epoch 177/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6176 - loss: 1.6793 - val_accuracy: 0.4357 - val_loss: 5.4278\n","Epoch 178/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6020 - loss: 1.7463 - val_accuracy: 0.4446 - val_loss: 5.4071\n","Epoch 179/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.5955 - loss: 1.7798 - val_accuracy: 0.4457 - val_loss: 5.4350\n","Epoch 180/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6172 - loss: 1.6775 - val_accuracy: 0.4339 - val_loss: 5.4961\n","Epoch 181/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6064 - loss: 1.7326 - val_accuracy: 0.4407 - val_loss: 5.4947\n","Epoch 182/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6061 - loss: 1.7289 - val_accuracy: 0.4410 - val_loss: 5.3823\n","Epoch 183/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6041 - loss: 1.7300 - val_accuracy: 0.4415 - val_loss: 5.3741\n","Epoch 184/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6095 - loss: 1.7185 - val_accuracy: 0.4316 - val_loss: 5.4966\n","Epoch 185/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6021 - loss: 1.7385 - val_accuracy: 0.4328 - val_loss: 5.5197\n","Epoch 186/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6068 - loss: 1.7212 - val_accuracy: 0.4418 - val_loss: 5.4738\n","Epoch 187/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6117 - loss: 1.6995 - val_accuracy: 0.4480 - val_loss: 5.4244\n","Epoch 188/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.6052 - loss: 1.7232 - val_accuracy: 0.4395 - val_loss: 5.4376\n","Epoch 189/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.6026 - loss: 1.7431 - val_accuracy: 0.4398 - val_loss: 5.4893\n","Epoch 190/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 2s/step - accuracy: 0.6013 - loss: 1.7293 - val_accuracy: 0.4382 - val_loss: 5.5101\n","Epoch 191/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.6121 - loss: 1.6883 - val_accuracy: 0.4414 - val_loss: 5.4689\n","Epoch 192/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - accuracy: 0.6132 - loss: 1.6865 - val_accuracy: 0.4435 - val_loss: 5.4548\n","Epoch 193/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.6026 - loss: 1.7320 - val_accuracy: 0.4412 - val_loss: 5.5214\n","Epoch 194/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.6037 - loss: 1.7156 - val_accuracy: 0.4328 - val_loss: 5.5248\n","Epoch 195/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6141 - loss: 1.6794 - val_accuracy: 0.4391 - val_loss: 5.4027\n","Epoch 196/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6114 - loss: 1.6743 - val_accuracy: 0.4409 - val_loss: 5.4471\n","Epoch 197/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6104 - loss: 1.6895 - val_accuracy: 0.4369 - val_loss: 5.5983\n","Epoch 198/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6166 - loss: 1.6585 - val_accuracy: 0.4369 - val_loss: 5.5910\n","Epoch 199/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.6098 - loss: 1.7021 - val_accuracy: 0.4386 - val_loss: 5.5273\n","Epoch 200/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - accuracy: 0.6123 - loss: 1.6726 - val_accuracy: 0.4440 - val_loss: 5.4400\n","Epoch 201/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step - accuracy: 0.6132 - loss: 1.6749 - val_accuracy: 0.4357 - val_loss: 5.4692\n","Epoch 202/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.6181 - loss: 1.6487 - val_accuracy: 0.4395 - val_loss: 5.4666\n","Epoch 203/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6112 - loss: 1.6852 - val_accuracy: 0.4388 - val_loss: 5.4987\n","Epoch 204/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 2s/step - accuracy: 0.6081 - loss: 1.6843 - val_accuracy: 0.4414 - val_loss: 5.4165\n","Epoch 205/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - accuracy: 0.6102 - loss: 1.6724 - val_accuracy: 0.4391 - val_loss: 5.4923\n","Epoch 206/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - accuracy: 0.6130 - loss: 1.6628 - val_accuracy: 0.4290 - val_loss: 5.5626\n","Epoch 207/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 2s/step - accuracy: 0.6173 - loss: 1.6346 - val_accuracy: 0.4327 - val_loss: 5.5104\n","Epoch 208/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6083 - loss: 1.6861 - val_accuracy: 0.4397 - val_loss: 5.4770\n","Epoch 209/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6169 - loss: 1.6557 - val_accuracy: 0.4394 - val_loss: 5.4687\n","Epoch 210/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6158 - loss: 1.6534 - val_accuracy: 0.4336 - val_loss: 5.5383\n","Epoch 211/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6075 - loss: 1.6814 - val_accuracy: 0.4355 - val_loss: 5.6220\n","Epoch 212/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6102 - loss: 1.6638 - val_accuracy: 0.4386 - val_loss: 5.4999\n","Epoch 213/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6261 - loss: 1.5942 - val_accuracy: 0.4421 - val_loss: 5.5077\n","Epoch 214/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6164 - loss: 1.6426 - val_accuracy: 0.4357 - val_loss: 5.4709\n","Epoch 215/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6117 - loss: 1.6506 - val_accuracy: 0.4367 - val_loss: 5.5952\n","Epoch 216/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6092 - loss: 1.6660 - val_accuracy: 0.4383 - val_loss: 5.5424\n","Epoch 217/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6182 - loss: 1.6345 - val_accuracy: 0.4391 - val_loss: 5.4635\n","Epoch 218/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6169 - loss: 1.6331 - val_accuracy: 0.4364 - val_loss: 5.5177\n","Epoch 219/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6183 - loss: 1.6227 - val_accuracy: 0.4273 - val_loss: 5.5587\n","Epoch 220/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6096 - loss: 1.6564 - val_accuracy: 0.4315 - val_loss: 5.5666\n","Epoch 221/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6268 - loss: 1.5881 - val_accuracy: 0.4396 - val_loss: 5.5154\n","Epoch 222/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6178 - loss: 1.6269 - val_accuracy: 0.4386 - val_loss: 5.5192\n","Epoch 223/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6224 - loss: 1.6015 - val_accuracy: 0.4267 - val_loss: 5.5512\n","Epoch 224/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6229 - loss: 1.5913 - val_accuracy: 0.4310 - val_loss: 5.5449\n","Epoch 225/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6202 - loss: 1.6018 - val_accuracy: 0.4408 - val_loss: 5.5971\n","Epoch 226/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6277 - loss: 1.5793 - val_accuracy: 0.4393 - val_loss: 5.4920\n","Epoch 227/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6186 - loss: 1.6084 - val_accuracy: 0.4357 - val_loss: 5.5326\n","Epoch 228/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6158 - loss: 1.6217 - val_accuracy: 0.4360 - val_loss: 5.5874\n","Epoch 229/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6200 - loss: 1.6170 - val_accuracy: 0.4386 - val_loss: 5.5962\n","Epoch 230/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6174 - loss: 1.6214 - val_accuracy: 0.4368 - val_loss: 5.5412\n","Epoch 231/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6202 - loss: 1.6184 - val_accuracy: 0.4350 - val_loss: 5.4988\n","Epoch 232/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6241 - loss: 1.5996 - val_accuracy: 0.4314 - val_loss: 5.6069\n","Epoch 233/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6144 - loss: 1.6257 - val_accuracy: 0.4343 - val_loss: 5.5422\n","Epoch 234/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6068 - loss: 1.6776 - val_accuracy: 0.4373 - val_loss: 5.5020\n","Epoch 235/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6178 - loss: 1.6174 - val_accuracy: 0.4438 - val_loss: 5.5136\n","Epoch 236/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6177 - loss: 1.6358 - val_accuracy: 0.4329 - val_loss: 5.5683\n","Epoch 237/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6128 - loss: 1.6320 - val_accuracy: 0.4325 - val_loss: 5.6118\n","Epoch 238/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6266 - loss: 1.5749 - val_accuracy: 0.4378 - val_loss: 5.5892\n","Epoch 239/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6269 - loss: 1.5769 - val_accuracy: 0.4379 - val_loss: 5.5319\n","Epoch 240/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6217 - loss: 1.5867 - val_accuracy: 0.4376 - val_loss: 5.5683\n","Epoch 241/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6110 - loss: 1.6392 - val_accuracy: 0.4347 - val_loss: 5.5682\n","Epoch 242/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6127 - loss: 1.6243 - val_accuracy: 0.4370 - val_loss: 5.5479\n","Epoch 243/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6168 - loss: 1.6327 - val_accuracy: 0.4386 - val_loss: 5.5651\n","Epoch 244/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6175 - loss: 1.6163 - val_accuracy: 0.4401 - val_loss: 5.5715\n","Epoch 245/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6265 - loss: 1.5775 - val_accuracy: 0.4250 - val_loss: 5.6227\n","Epoch 246/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6144 - loss: 1.6247 - val_accuracy: 0.4364 - val_loss: 5.6525\n","Epoch 247/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6176 - loss: 1.6113 - val_accuracy: 0.4377 - val_loss: 5.5332\n","Epoch 248/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6239 - loss: 1.5888 - val_accuracy: 0.4373 - val_loss: 5.5542\n","Epoch 249/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6217 - loss: 1.5986 - val_accuracy: 0.4289 - val_loss: 5.6389\n","Epoch 250/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6202 - loss: 1.6005 - val_accuracy: 0.4345 - val_loss: 5.6936\n","Epoch 251/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.6163 - loss: 1.6244 - val_accuracy: 0.4351 - val_loss: 5.6120\n","Epoch 252/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6185 - loss: 1.6003 - val_accuracy: 0.4393 - val_loss: 5.5806\n","Epoch 253/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6268 - loss: 1.5706 - val_accuracy: 0.4373 - val_loss: 5.5357\n","Epoch 254/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6198 - loss: 1.6022 - val_accuracy: 0.4355 - val_loss: 5.6206\n","Epoch 255/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6169 - loss: 1.6168 - val_accuracy: 0.4393 - val_loss: 5.6730\n","Epoch 256/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6193 - loss: 1.6046 - val_accuracy: 0.4302 - val_loss: 5.5880\n","Epoch 257/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6205 - loss: 1.6042 - val_accuracy: 0.4383 - val_loss: 5.5726\n","Epoch 258/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6142 - loss: 1.6239 - val_accuracy: 0.4331 - val_loss: 5.7394\n","Epoch 259/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.6147 - loss: 1.5997 - val_accuracy: 0.4361 - val_loss: 5.7023\n","Epoch 260/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6127 - loss: 1.6286 - val_accuracy: 0.4377 - val_loss: 5.5292\n","Epoch 261/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6060 - loss: 1.6497 - val_accuracy: 0.4410 - val_loss: 5.5872\n","Epoch 262/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6308 - loss: 1.5527 - val_accuracy: 0.4315 - val_loss: 5.6705\n","Epoch 263/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6150 - loss: 1.6163 - val_accuracy: 0.4343 - val_loss: 5.6952\n","Epoch 264/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6229 - loss: 1.5716 - val_accuracy: 0.4379 - val_loss: 5.6446\n","Epoch 265/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.6225 - loss: 1.5694 - val_accuracy: 0.4402 - val_loss: 5.5621\n","Epoch 266/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6242 - loss: 1.5692 - val_accuracy: 0.4341 - val_loss: 5.6083\n","Epoch 267/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6174 - loss: 1.5959 - val_accuracy: 0.4323 - val_loss: 5.6897\n","Epoch 268/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6328 - loss: 1.5290 - val_accuracy: 0.4358 - val_loss: 5.6478\n","Epoch 269/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6158 - loss: 1.6138 - val_accuracy: 0.4382 - val_loss: 5.5892\n","Epoch 270/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6278 - loss: 1.5515 - val_accuracy: 0.4383 - val_loss: 5.6205\n","Epoch 271/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6129 - loss: 1.6085 - val_accuracy: 0.4293 - val_loss: 5.6763\n","Epoch 272/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6295 - loss: 1.5550 - val_accuracy: 0.4360 - val_loss: 5.6976\n","Epoch 273/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6184 - loss: 1.5829 - val_accuracy: 0.4343 - val_loss: 5.6224\n","Epoch 274/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6252 - loss: 1.5593 - val_accuracy: 0.4381 - val_loss: 5.6473\n","Epoch 275/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6068 - loss: 1.6365 - val_accuracy: 0.4346 - val_loss: 5.7036\n","Epoch 276/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6177 - loss: 1.5938 - val_accuracy: 0.4309 - val_loss: 5.7450\n","Epoch 277/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6236 - loss: 1.5564 - val_accuracy: 0.4385 - val_loss: 5.6774\n","Epoch 278/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6209 - loss: 1.5870 - val_accuracy: 0.4407 - val_loss: 5.6169\n","Epoch 279/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6232 - loss: 1.5620 - val_accuracy: 0.4357 - val_loss: 5.6583\n","Epoch 280/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6138 - loss: 1.6104 - val_accuracy: 0.4311 - val_loss: 5.7314\n","Epoch 281/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6241 - loss: 1.5673 - val_accuracy: 0.4322 - val_loss: 5.6685\n","Epoch 282/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6276 - loss: 1.5495 - val_accuracy: 0.4317 - val_loss: 5.6521\n","Epoch 283/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6286 - loss: 1.5297 - val_accuracy: 0.4339 - val_loss: 5.6877\n","Epoch 284/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6279 - loss: 1.5438 - val_accuracy: 0.4258 - val_loss: 5.7240\n","Epoch 285/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6271 - loss: 1.5401 - val_accuracy: 0.4258 - val_loss: 5.7541\n","Epoch 286/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6382 - loss: 1.4988 - val_accuracy: 0.4326 - val_loss: 5.7030\n","Epoch 287/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6222 - loss: 1.5493 - val_accuracy: 0.4363 - val_loss: 5.6473\n","Epoch 288/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6264 - loss: 1.5407 - val_accuracy: 0.4330 - val_loss: 5.7138\n","Epoch 289/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6243 - loss: 1.5700 - val_accuracy: 0.4289 - val_loss: 5.7580\n","Epoch 290/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6234 - loss: 1.5654 - val_accuracy: 0.4325 - val_loss: 5.7930\n","Epoch 291/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6281 - loss: 1.5430 - val_accuracy: 0.4381 - val_loss: 5.6569\n","Epoch 292/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6235 - loss: 1.5478 - val_accuracy: 0.4356 - val_loss: 5.6482\n","Epoch 293/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6256 - loss: 1.5453 - val_accuracy: 0.4306 - val_loss: 5.7456\n","Epoch 294/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6242 - loss: 1.5562 - val_accuracy: 0.4320 - val_loss: 5.7425\n","Epoch 295/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6257 - loss: 1.5380 - val_accuracy: 0.4317 - val_loss: 5.7178\n","Epoch 296/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6263 - loss: 1.5400 - val_accuracy: 0.4340 - val_loss: 5.6991\n","Epoch 297/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6235 - loss: 1.5383 - val_accuracy: 0.4345 - val_loss: 5.7476\n","Epoch 298/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6304 - loss: 1.5154 - val_accuracy: 0.4272 - val_loss: 5.7940\n","Epoch 299/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6229 - loss: 1.5515 - val_accuracy: 0.4378 - val_loss: 5.6576\n","Epoch 300/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6288 - loss: 1.5274 - val_accuracy: 0.4383 - val_loss: 5.6799\n","Epoch 301/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6277 - loss: 1.5262 - val_accuracy: 0.4318 - val_loss: 5.7467\n","Epoch 302/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6412 - loss: 1.4746 - val_accuracy: 0.4300 - val_loss: 5.7925\n","Epoch 303/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6266 - loss: 1.5328 - val_accuracy: 0.4360 - val_loss: 5.7817\n","Epoch 304/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6328 - loss: 1.5174 - val_accuracy: 0.4390 - val_loss: 5.7045\n","Epoch 305/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6294 - loss: 1.5178 - val_accuracy: 0.4286 - val_loss: 5.6957\n","Epoch 306/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6294 - loss: 1.5215 - val_accuracy: 0.4344 - val_loss: 5.7975\n","Epoch 307/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6306 - loss: 1.5168 - val_accuracy: 0.4334 - val_loss: 5.7322\n","Epoch 308/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6270 - loss: 1.5182 - val_accuracy: 0.4326 - val_loss: 5.7288\n","Epoch 309/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6293 - loss: 1.5205 - val_accuracy: 0.4379 - val_loss: 5.7433\n","Epoch 310/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6316 - loss: 1.5100 - val_accuracy: 0.4291 - val_loss: 5.7817\n","Epoch 311/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6297 - loss: 1.5130 - val_accuracy: 0.4318 - val_loss: 5.7991\n","Epoch 312/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6274 - loss: 1.5213 - val_accuracy: 0.4405 - val_loss: 5.6996\n","Epoch 313/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6333 - loss: 1.5020 - val_accuracy: 0.4430 - val_loss: 5.7063\n","Epoch 314/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6265 - loss: 1.5279 - val_accuracy: 0.4317 - val_loss: 5.7792\n","Epoch 315/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 2s/step - accuracy: 0.6247 - loss: 1.5254 - val_accuracy: 0.4269 - val_loss: 5.8329\n","Epoch 316/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6329 - loss: 1.4994 - val_accuracy: 0.4351 - val_loss: 5.7697\n","Epoch 317/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6361 - loss: 1.4846 - val_accuracy: 0.4411 - val_loss: 5.7022\n","Epoch 318/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6230 - loss: 1.5372 - val_accuracy: 0.4296 - val_loss: 5.6841\n","Epoch 319/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6323 - loss: 1.5051 - val_accuracy: 0.4286 - val_loss: 5.7899\n","Epoch 320/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.6367 - loss: 1.4732 - val_accuracy: 0.4303 - val_loss: 5.7594\n","Epoch 321/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - accuracy: 0.6288 - loss: 1.5054 - val_accuracy: 0.4300 - val_loss: 5.7367\n","Epoch 322/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.6358 - loss: 1.4709 - val_accuracy: 0.4366 - val_loss: 5.7753\n","Epoch 323/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6300 - loss: 1.4916 - val_accuracy: 0.4270 - val_loss: 5.8268\n","Epoch 324/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.6369 - loss: 1.4784 - val_accuracy: 0.4311 - val_loss: 5.8231\n","Epoch 325/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6331 - loss: 1.4847 - val_accuracy: 0.4308 - val_loss: 5.7671\n","Epoch 326/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6312 - loss: 1.4929 - val_accuracy: 0.4378 - val_loss: 5.7105\n","Epoch 327/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6323 - loss: 1.4971 - val_accuracy: 0.4309 - val_loss: 5.8242\n","Epoch 328/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6393 - loss: 1.4705 - val_accuracy: 0.4271 - val_loss: 5.8153\n","Epoch 329/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6240 - loss: 1.5225 - val_accuracy: 0.4341 - val_loss: 5.7805\n","Epoch 330/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6380 - loss: 1.4598 - val_accuracy: 0.4417 - val_loss: 5.7022\n","Epoch 331/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6357 - loss: 1.4742 - val_accuracy: 0.4293 - val_loss: 5.7321\n","Epoch 332/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6378 - loss: 1.4621 - val_accuracy: 0.4346 - val_loss: 5.7891\n","Epoch 333/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6361 - loss: 1.4769 - val_accuracy: 0.4336 - val_loss: 5.7570\n","Epoch 334/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6332 - loss: 1.4770 - val_accuracy: 0.4333 - val_loss: 5.7216\n","Epoch 335/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6362 - loss: 1.4671 - val_accuracy: 0.4317 - val_loss: 5.7188\n","Epoch 336/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6379 - loss: 1.4564 - val_accuracy: 0.4284 - val_loss: 5.7762\n","Epoch 337/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6372 - loss: 1.4604 - val_accuracy: 0.4336 - val_loss: 5.8406\n","Epoch 338/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6334 - loss: 1.4657 - val_accuracy: 0.4323 - val_loss: 5.7366\n","Epoch 339/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6345 - loss: 1.4788 - val_accuracy: 0.4330 - val_loss: 5.7207\n","Epoch 340/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6373 - loss: 1.4588 - val_accuracy: 0.4329 - val_loss: 5.8216\n","Epoch 341/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6350 - loss: 1.4810 - val_accuracy: 0.4296 - val_loss: 5.8700\n","Epoch 342/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.6411 - loss: 1.4386 - val_accuracy: 0.4355 - val_loss: 5.7726\n","Epoch 343/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6377 - loss: 1.4549 - val_accuracy: 0.4286 - val_loss: 5.6929\n","Epoch 344/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - accuracy: 0.6294 - loss: 1.4758 - val_accuracy: 0.4363 - val_loss: 5.7185\n","Epoch 345/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6418 - loss: 1.4302 - val_accuracy: 0.4288 - val_loss: 5.8083\n","Epoch 346/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.6342 - loss: 1.4796 - val_accuracy: 0.4308 - val_loss: 5.7809\n","Epoch 347/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6358 - loss: 1.4572 - val_accuracy: 0.4368 - val_loss: 5.6997\n","Epoch 348/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - accuracy: 0.6280 - loss: 1.5068 - val_accuracy: 0.4321 - val_loss: 5.7630\n","Epoch 349/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6367 - loss: 1.4646 - val_accuracy: 0.4263 - val_loss: 5.8478\n","Epoch 350/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6300 - loss: 1.4908 - val_accuracy: 0.4308 - val_loss: 5.8038\n","Epoch 351/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6306 - loss: 1.4785 - val_accuracy: 0.4252 - val_loss: 5.7602\n","Epoch 352/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6432 - loss: 1.4255 - val_accuracy: 0.4394 - val_loss: 5.7144\n","Epoch 353/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6232 - loss: 1.5123 - val_accuracy: 0.4290 - val_loss: 5.8914\n","Epoch 354/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.6393 - loss: 1.4551 - val_accuracy: 0.4279 - val_loss: 5.8692\n","Epoch 355/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6350 - loss: 1.4702 - val_accuracy: 0.4368 - val_loss: 5.8135\n","Epoch 356/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.6395 - loss: 1.4587 - val_accuracy: 0.4368 - val_loss: 5.7482\n","Epoch 357/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6328 - loss: 1.4764 - val_accuracy: 0.4328 - val_loss: 5.7620\n","Epoch 358/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.6371 - loss: 1.4555 - val_accuracy: 0.4293 - val_loss: 5.8854\n","Epoch 359/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6358 - loss: 1.4647 - val_accuracy: 0.4327 - val_loss: 5.7766\n","Epoch 360/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.6328 - loss: 1.4752 - val_accuracy: 0.4367 - val_loss: 5.7875\n","Epoch 361/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6363 - loss: 1.4665 - val_accuracy: 0.4373 - val_loss: 5.7884\n","Epoch 362/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6391 - loss: 1.4544 - val_accuracy: 0.4271 - val_loss: 5.8038\n","Epoch 363/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6225 - loss: 1.5171 - val_accuracy: 0.4254 - val_loss: 5.8721\n","Epoch 364/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.6445 - loss: 1.4249 - val_accuracy: 0.4336 - val_loss: 5.7992\n","Epoch 365/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.6280 - loss: 1.4926 - val_accuracy: 0.4331 - val_loss: 5.7831\n","Epoch 366/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6356 - loss: 1.4704 - val_accuracy: 0.4274 - val_loss: 5.8607\n","Epoch 367/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6474 - loss: 1.4091 - val_accuracy: 0.4340 - val_loss: 5.9061\n","Epoch 368/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6303 - loss: 1.4821 - val_accuracy: 0.4355 - val_loss: 5.8126\n","Epoch 369/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6446 - loss: 1.4219 - val_accuracy: 0.4376 - val_loss: 5.8001\n","Epoch 370/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6418 - loss: 1.4340 - val_accuracy: 0.4342 - val_loss: 5.8006\n","Epoch 371/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6269 - loss: 1.4937 - val_accuracy: 0.4276 - val_loss: 5.9064\n","Epoch 372/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6327 - loss: 1.4774 - val_accuracy: 0.4315 - val_loss: 5.8940\n","Epoch 373/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6347 - loss: 1.4619 - val_accuracy: 0.4308 - val_loss: 5.8049\n","Epoch 374/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6428 - loss: 1.4234 - val_accuracy: 0.4314 - val_loss: 5.8153\n","Epoch 375/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - accuracy: 0.6398 - loss: 1.4300 - val_accuracy: 0.4295 - val_loss: 5.8968\n","Epoch 376/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6354 - loss: 1.4746 - val_accuracy: 0.4297 - val_loss: 5.8477\n","Epoch 377/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.6420 - loss: 1.4248 - val_accuracy: 0.4393 - val_loss: 5.8095\n","Epoch 378/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6288 - loss: 1.4785 - val_accuracy: 0.4344 - val_loss: 5.7863\n","Epoch 379/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6341 - loss: 1.4644 - val_accuracy: 0.4246 - val_loss: 5.9032\n","Epoch 380/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6313 - loss: 1.4671 - val_accuracy: 0.4363 - val_loss: 5.9042\n","Epoch 381/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6421 - loss: 1.4313 - val_accuracy: 0.4351 - val_loss: 5.8616\n","Epoch 382/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6344 - loss: 1.4676 - val_accuracy: 0.4382 - val_loss: 5.8506\n","Epoch 383/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6369 - loss: 1.4464 - val_accuracy: 0.4313 - val_loss: 5.8137\n","Epoch 384/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6407 - loss: 1.4428 - val_accuracy: 0.4297 - val_loss: 5.8697\n","Epoch 385/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6422 - loss: 1.4409 - val_accuracy: 0.4283 - val_loss: 5.9020\n","Epoch 386/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6352 - loss: 1.4442 - val_accuracy: 0.4266 - val_loss: 5.8210\n","Epoch 387/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6406 - loss: 1.4482 - val_accuracy: 0.4308 - val_loss: 5.8549\n","Epoch 388/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6372 - loss: 1.4398 - val_accuracy: 0.4247 - val_loss: 5.9063\n","Epoch 389/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6448 - loss: 1.4180 - val_accuracy: 0.4235 - val_loss: 5.9522\n","Epoch 390/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6393 - loss: 1.4382 - val_accuracy: 0.4329 - val_loss: 5.8257\n","Epoch 391/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6490 - loss: 1.3967 - val_accuracy: 0.4339 - val_loss: 5.8669\n","Epoch 392/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6319 - loss: 1.4664 - val_accuracy: 0.4290 - val_loss: 5.9530\n","Epoch 393/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6358 - loss: 1.4586 - val_accuracy: 0.4251 - val_loss: 5.9676\n","Epoch 394/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - accuracy: 0.6379 - loss: 1.4346 - val_accuracy: 0.4319 - val_loss: 5.8846\n","Epoch 395/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6438 - loss: 1.4227 - val_accuracy: 0.4377 - val_loss: 5.7978\n","Epoch 396/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6274 - loss: 1.4819 - val_accuracy: 0.4322 - val_loss: 5.8424\n","Epoch 397/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6399 - loss: 1.4249 - val_accuracy: 0.4284 - val_loss: 5.9494\n","Epoch 398/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6388 - loss: 1.4332 - val_accuracy: 0.4315 - val_loss: 5.9305\n","Epoch 399/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6434 - loss: 1.4217 - val_accuracy: 0.4363 - val_loss: 5.8420\n","Epoch 400/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6320 - loss: 1.4625 - val_accuracy: 0.4368 - val_loss: 5.8556\n","Epoch 401/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6418 - loss: 1.4222 - val_accuracy: 0.4250 - val_loss: 5.9327\n","Epoch 402/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6352 - loss: 1.4605 - val_accuracy: 0.4327 - val_loss: 5.9561\n","Epoch 403/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6323 - loss: 1.4666 - val_accuracy: 0.4366 - val_loss: 5.8843\n","Epoch 404/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6353 - loss: 1.4410 - val_accuracy: 0.4352 - val_loss: 5.8695\n","Epoch 405/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6337 - loss: 1.4468 - val_accuracy: 0.4265 - val_loss: 5.9151\n","Epoch 406/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6392 - loss: 1.4255 - val_accuracy: 0.4267 - val_loss: 5.9650\n","Epoch 407/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6431 - loss: 1.4136 - val_accuracy: 0.4327 - val_loss: 5.9572\n","Epoch 408/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6364 - loss: 1.4356 - val_accuracy: 0.4399 - val_loss: 5.8437\n","Epoch 409/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6407 - loss: 1.4130 - val_accuracy: 0.4278 - val_loss: 5.8515\n","Epoch 410/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6390 - loss: 1.4130 - val_accuracy: 0.4306 - val_loss: 5.9703\n","Epoch 411/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6487 - loss: 1.3874 - val_accuracy: 0.4348 - val_loss: 5.8735\n","Epoch 412/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6515 - loss: 1.3807 - val_accuracy: 0.4329 - val_loss: 5.8250\n","Epoch 413/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6418 - loss: 1.4150 - val_accuracy: 0.4329 - val_loss: 5.8603\n","Epoch 414/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6433 - loss: 1.4015 - val_accuracy: 0.4293 - val_loss: 5.9347\n","Epoch 415/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6429 - loss: 1.4135 - val_accuracy: 0.4249 - val_loss: 5.9294\n","Epoch 416/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6488 - loss: 1.3812 - val_accuracy: 0.4335 - val_loss: 5.8542\n","Epoch 417/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6439 - loss: 1.4047 - val_accuracy: 0.4337 - val_loss: 5.8553\n","Epoch 418/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6510 - loss: 1.3796 - val_accuracy: 0.4198 - val_loss: 5.9424\n","Epoch 419/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.6406 - loss: 1.4146 - val_accuracy: 0.4242 - val_loss: 6.0290\n","Epoch 420/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6437 - loss: 1.3994 - val_accuracy: 0.4343 - val_loss: 5.8932\n","Epoch 421/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6468 - loss: 1.3887 - val_accuracy: 0.4407 - val_loss: 5.8690\n","Epoch 422/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6412 - loss: 1.4065 - val_accuracy: 0.4320 - val_loss: 5.8690\n","Epoch 423/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6340 - loss: 1.4376 - val_accuracy: 0.4300 - val_loss: 5.9332\n","Epoch 424/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6422 - loss: 1.4069 - val_accuracy: 0.4288 - val_loss: 5.9463\n","Epoch 425/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 2s/step - accuracy: 0.6448 - loss: 1.4070 - val_accuracy: 0.4303 - val_loss: 5.8675\n","Epoch 426/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.6502 - loss: 1.3718 - val_accuracy: 0.4336 - val_loss: 5.9272\n","Epoch 427/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.6394 - loss: 1.4227 - val_accuracy: 0.4244 - val_loss: 5.9850\n","Epoch 428/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6421 - loss: 1.3901 - val_accuracy: 0.4269 - val_loss: 5.9784\n","Epoch 429/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 2s/step - accuracy: 0.6438 - loss: 1.3969 - val_accuracy: 0.4341 - val_loss: 5.8843\n","Epoch 430/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6427 - loss: 1.4057 - val_accuracy: 0.4315 - val_loss: 5.8587\n","Epoch 431/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6487 - loss: 1.3772 - val_accuracy: 0.4248 - val_loss: 6.0107\n","Epoch 432/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6425 - loss: 1.4046 - val_accuracy: 0.4301 - val_loss: 5.9842\n","Epoch 433/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6404 - loss: 1.4212 - val_accuracy: 0.4351 - val_loss: 5.9562\n","Epoch 434/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6464 - loss: 1.3895 - val_accuracy: 0.4346 - val_loss: 5.8271\n","Epoch 435/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6449 - loss: 1.3868 - val_accuracy: 0.4339 - val_loss: 5.8708\n","Epoch 436/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6449 - loss: 1.3931 - val_accuracy: 0.4300 - val_loss: 6.0148\n","Epoch 437/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6461 - loss: 1.3922 - val_accuracy: 0.4295 - val_loss: 5.9557\n","Epoch 438/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6397 - loss: 1.4158 - val_accuracy: 0.4350 - val_loss: 5.8667\n","Epoch 439/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6461 - loss: 1.3874 - val_accuracy: 0.4337 - val_loss: 5.9364\n","Epoch 440/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.6417 - loss: 1.3955 - val_accuracy: 0.4259 - val_loss: 5.9909\n","Epoch 441/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6381 - loss: 1.3961 - val_accuracy: 0.4235 - val_loss: 6.0272\n","Epoch 442/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6529 - loss: 1.3518 - val_accuracy: 0.4336 - val_loss: 5.8988\n","Epoch 443/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6419 - loss: 1.3980 - val_accuracy: 0.4347 - val_loss: 5.9145\n","Epoch 444/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.6454 - loss: 1.3822 - val_accuracy: 0.4277 - val_loss: 5.9879\n","Epoch 445/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6429 - loss: 1.3955 - val_accuracy: 0.4261 - val_loss: 5.9804\n","Epoch 446/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6508 - loss: 1.3530 - val_accuracy: 0.4353 - val_loss: 5.9625\n","Epoch 447/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.6451 - loss: 1.3928 - val_accuracy: 0.4362 - val_loss: 5.8919\n","Epoch 448/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6486 - loss: 1.3758 - val_accuracy: 0.4296 - val_loss: 5.9012\n","Epoch 449/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6509 - loss: 1.3506 - val_accuracy: 0.4303 - val_loss: 5.9325\n","Epoch 450/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6520 - loss: 1.3635 - val_accuracy: 0.4296 - val_loss: 5.9446\n","Epoch 451/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.6551 - loss: 1.3373 - val_accuracy: 0.4347 - val_loss: 5.8780\n","Epoch 452/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.6509 - loss: 1.3566 - val_accuracy: 0.4313 - val_loss: 5.9625\n","Epoch 453/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6512 - loss: 1.3557 - val_accuracy: 0.4213 - val_loss: 5.9534\n","Epoch 454/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6454 - loss: 1.3866 - val_accuracy: 0.4296 - val_loss: 5.9770\n","Epoch 455/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6469 - loss: 1.3724 - val_accuracy: 0.4363 - val_loss: 5.8967\n","Epoch 456/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6564 - loss: 1.3277 - val_accuracy: 0.4360 - val_loss: 5.9028\n","Epoch 457/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6443 - loss: 1.3772 - val_accuracy: 0.4259 - val_loss: 6.0110\n","Epoch 458/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6497 - loss: 1.3541 - val_accuracy: 0.4265 - val_loss: 6.0184\n","Epoch 459/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6503 - loss: 1.3585 - val_accuracy: 0.4316 - val_loss: 5.9785\n","Epoch 460/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6474 - loss: 1.3684 - val_accuracy: 0.4358 - val_loss: 5.9131\n","Epoch 461/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 0.6504 - loss: 1.3686 - val_accuracy: 0.4321 - val_loss: 5.8957\n","Epoch 462/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6484 - loss: 1.3780 - val_accuracy: 0.4286 - val_loss: 6.0010\n","Epoch 463/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6382 - loss: 1.4081 - val_accuracy: 0.4308 - val_loss: 5.9588\n","Epoch 464/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.6565 - loss: 1.3381 - val_accuracy: 0.4316 - val_loss: 5.9325\n","Epoch 465/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6475 - loss: 1.3699 - val_accuracy: 0.4328 - val_loss: 5.9574\n","Epoch 466/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6491 - loss: 1.3627 - val_accuracy: 0.4182 - val_loss: 6.0035\n","Epoch 467/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.6541 - loss: 1.3490 - val_accuracy: 0.4279 - val_loss: 5.9633\n","Epoch 468/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 2s/step - accuracy: 0.6499 - loss: 1.3637 - val_accuracy: 0.4303 - val_loss: 5.9545\n","Epoch 469/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 2s/step - accuracy: 0.6491 - loss: 1.3607 - val_accuracy: 0.4352 - val_loss: 5.9648\n","Epoch 470/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.6500 - loss: 1.3631 - val_accuracy: 0.4265 - val_loss: 6.0057\n","Epoch 471/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 2s/step - accuracy: 0.6484 - loss: 1.3682 - val_accuracy: 0.4247 - val_loss: 6.0505\n","Epoch 472/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 2s/step - accuracy: 0.6467 - loss: 1.3582 - val_accuracy: 0.4297 - val_loss: 5.9900\n","Epoch 473/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 2s/step - accuracy: 0.6458 - loss: 1.3848 - val_accuracy: 0.4398 - val_loss: 5.8703\n","Epoch 474/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - accuracy: 0.6572 - loss: 1.3185 - val_accuracy: 0.4290 - val_loss: 5.9424\n","Epoch 475/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - accuracy: 0.6542 - loss: 1.3380 - val_accuracy: 0.4314 - val_loss: 5.9803\n","Epoch 476/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.6469 - loss: 1.3668 - val_accuracy: 0.4294 - val_loss: 5.9692\n","Epoch 477/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6537 - loss: 1.3339 - val_accuracy: 0.4292 - val_loss: 6.0235\n","Epoch 478/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6503 - loss: 1.3485 - val_accuracy: 0.4282 - val_loss: 5.9966\n","Epoch 479/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6441 - loss: 1.3830 - val_accuracy: 0.4209 - val_loss: 5.9652\n","Epoch 480/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6576 - loss: 1.3228 - val_accuracy: 0.4292 - val_loss: 6.0625\n","Epoch 481/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6455 - loss: 1.3867 - val_accuracy: 0.4318 - val_loss: 6.0281\n","Epoch 482/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6498 - loss: 1.3650 - val_accuracy: 0.4325 - val_loss: 5.9652\n","Epoch 483/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6481 - loss: 1.3689 - val_accuracy: 0.4244 - val_loss: 6.0025\n","Epoch 484/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6524 - loss: 1.3447 - val_accuracy: 0.4308 - val_loss: 6.1028\n","Epoch 485/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6412 - loss: 1.3896 - val_accuracy: 0.4322 - val_loss: 6.0112\n","Epoch 486/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.6427 - loss: 1.3868 - val_accuracy: 0.4376 - val_loss: 5.9384\n","Epoch 487/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - accuracy: 0.6568 - loss: 1.3296 - val_accuracy: 0.4335 - val_loss: 5.9635\n","Epoch 488/2000\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.6426 - loss: 1.3931 - val_accuracy: 0.4249 - val_loss: 6.0264\n","Epoch 489/2000\n","\u001b[1m 45/112\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 1s/step - accuracy: 0.6641 - loss: 1.3032"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","import string\n","import re\n","import unicodedata\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import Callback\n","# Load data\n","data = pd.read_csv(\"chat_health.csv\")\n","data = data.head(2000)\n","\n","# Define function to convert unicode to ASCII\n","def unicode_to_ascii(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                   if unicodedata.category(c) != 'Mn')\n","\n","# Define text cleaning function\n","def clean_text(text):\n","    text = unicode_to_ascii(text.lower().strip())\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\"\\r\", \"\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"what's\", \"that is\", text)\n","    text = re.sub(r\"where's\", \"where is\", text)\n","    text = re.sub(r\"how's\", \"how is\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'ve\", \" have\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"\\'d\", \" would\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"n't\", \" not\", text)\n","    text = re.sub(r\"n'\", \"ng\", text)\n","    text = re.sub(r\"'bout\", \"about\", text)\n","    text = re.sub(r\"'til\", \"until\", text)\n","    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    text = re.sub(\"(\\\\W)\",\" \",text)\n","    text = re.sub('\\S*\\d\\S*\\s*','', text)\n","    return text\n","\n","data[\"short_question\"] = data.short_question.apply(clean_text)\n","data[\"short_answer\"] = data.short_answer.apply(clean_text)\n","\n","# Text preprocessing\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(data['short_question'].tolist() + data['short_answer'].tolist())\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","questions_seq = tokenizer.texts_to_sequences(data['short_question'])\n","answers_seq = tokenizer.texts_to_sequences(data['short_answer'])\n","\n","max_length = max(max(len(x) for x in questions_seq), max(len(x) for x in answers_seq))\n","questions_padded = pad_sequences(questions_seq, maxlen=max_length, padding='post')\n","answers_padded = pad_sequences(answers_seq, maxlen=max_length, padding='post')\n","\n","# Split dataset\n","train_questions, val_questions, train_answers, val_answers = train_test_split(\n","    questions_padded, answers_padded, test_size=0.1, random_state=42)\n","\n","# Prepare training and validation datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_questions, train_answers))\n","train_dataset = train_dataset.shuffle(buffer_size=10000).batch(16).repeat()\n","\n","val_dataset = tf.data.Dataset.from_tensor_slices((val_questions, val_answers))\n","val_dataset = val_dataset.batch(16).repeat()\n","\n","# Build model\n","model = Sequential([\n","    Embedding(vocab_size, 128),\n","    Bidirectional(GRU(256, return_sequences=True)),\n","    Dropout(0.5),\n","    BatchNormalization(),\n","    Bidirectional(GRU(256, return_sequences=True)),\n","    Dropout(0.5),\n","    Dense(vocab_size, activation='softmax')\n","])\n","\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Adjust batch_size or directly use the entire dataset\n","batch_size = 16\n","class CombinedStoppingCallback(Callback):\n","    def __init__(self, loss_threshold=0.01, improvement_threshold=0.01, patience=200):\n","        super(CombinedStoppingCallback, self).__init__()\n","        self.loss_threshold = loss_threshold  # Stop training if loss is below this value\n","        self.improvement_threshold = improvement_threshold  # Consider stopping if improvement is less than this value\n","        self.patience = patience  # Max consecutive epochs to wait before deciding to stop\n","        self.best_loss = float('inf')\n","        self.best_epoch = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_loss = logs.get('loss')\n","        if current_loss is None:\n","            return\n","\n","        # Check if the loss has reached below the threshold\n","        if current_loss < self.loss_threshold:\n","            print(f\"\\nEpoch {epoch}: Stopping training as loss {current_loss} is below threshold {self.loss_threshold}.\")\n","            self.model.stop_training = True\n","\n","        # Check if there is a significant improvement in loss\n","        if current_loss < self.best_loss:\n","            self.best_loss = current_loss\n","            self.best_epoch = epoch\n","        else:\n","            # Check if it has been 'patience' epochs since the last best loss and the improvement is not enough\n","            if (epoch - self.best_epoch) >= self.patience and (self.best_loss - current_loss) < self.improvement_threshold:\n","                print(f\"\\nEpoch {epoch}: No significant improvement in loss for {self.patience} epochs. Stopping training.\")\n","                self.model.stop_training = True\n","\n","# Create an instance of CombinedStoppingCallback\n","stopping_callback = CombinedStoppingCallback(loss_threshold=0.1, improvement_threshold=0.1, patience=30)\n","\n","# Use the model and save training history\n","history = model.fit(\n","    train_dataset,\n","    epochs=2000,\n","    steps_per_epoch=max(1, len(train_questions) // batch_size),\n","    validation_data=val_dataset,\n","    validation_steps=max(1, len(val_questions) // batch_size),\n","    callbacks=[stopping_callback]\n",")"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"qP6Z_BbTnia-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_weights('GRU_2000.weights.h5')\n","\n","\n","# save Tokenizer\n","import pickle\n","with open('tokenizer_GRU_2000.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"nnO3Bi2qBZpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download('GRU_2000.weights.h5')\n","files.download('tokenizer_GRU_2000.pickle')"],"metadata":{"id":"V-zLvaJoFUSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size"],"metadata":{"id":"ER-9V-67q-b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length"],"metadata":{"id":"RmfHdA5uswoE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","import pickle\n","\n","\n","\n","model1 = Sequential([\n","    Embedding(vocab_size, 128),\n","    Bidirectional(GRU(256, return_sequences=True)),\n","    Dropout(0.5),\n","    BatchNormalization(),\n","    Bidirectional(GRU(256, return_sequences=True)),\n","    Dropout(0.5),\n","    Dense(vocab_size, activation='softmax')\n","])\n","\n","model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model1.build(input_shape=(None, max_length))\n","\n","\n","model1.load_weights('my_model_weights.weights.h5')\n","model1.summary()"],"metadata":{"id":"v39XrjQhMqcF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate answer\n","def generate_answer(question,model):\n","    question_seq = tokenizer.texts_to_sequences([question])\n","    question_padded = pad_sequences(question_seq, maxlen=max_length, padding='post')\n","    prediction = model.predict(question_padded)\n","    predicted_indices = np.argmax(prediction, axis=-1)[0]\n","    predicted_words = ' '.join([tokenizer.index_word[i] for i in predicted_indices if i != 0])\n","    return predicted_words"],"metadata":{"id":"-deuvQX_PS-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testData = pd.read_csv('chat_health.csv').head(50)"],"metadata":{"id":"KYj5maPcP8ii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu\n","testData['generated_answer'] = testData['short_question'].apply(lambda q: generate_answer(q, model1))\n","\n","references = testData['short_answer'].apply(lambda a: [a.split()]).tolist()\n","candidates = testData['generated_answer'].apply(lambda a: a.split()).tolist()\n","\n","bleu_score = corpus_bleu(references, candidates)\n","print(\"BLEU Score:\", bleu_score)"],"metadata":{"id":"mzu4S6LDPz5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","start_time = time.time()\n","testData['generated_answer'] = testData['short_question'].head(50).apply(lambda q: generate_answer(q, model1))\n","end_time = time.time()\n","response_time = end_time - start_time\n","average_response_time = response_time / 50\n","\n","print(f\"Average response time per record: {average_response_time} seconds\")"],"metadata":{"id":"_P12RjplD2-1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"X4vD3gJQ_Tr4"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# Plotting loss curves\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Loss Curves')\n","plt.show()\n","\n","# Plotting accuracy curves\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Learning Curves')\n","plt.show()"],"metadata":{"id":"U3rBP4re9zm8"},"execution_count":null,"outputs":[]}]}